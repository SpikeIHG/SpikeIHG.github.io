<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Winter&#39;s</title>
  
  
  <link href="https://spikeihg.github.io/atom.xml" rel="self"/>
  
  <link href="https://spikeihg.github.io/"/>
  <updated>2024-03-13T12:56:17.219Z</updated>
  <id>https://spikeihg.github.io/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>GoMars</title>
    <link href="https://spikeihg.github.io/2024/03/05/GoMars/"/>
    <id>https://spikeihg.github.io/2024/03/05/GoMars/</id>
    <published>2024-03-05T00:37:12.000Z</published>
    <updated>2024-03-13T12:56:17.219Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GoMars"><a href="#GoMars" class="headerlink" title="GoMars"></a>GoMars</h1><h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><ul><li>fortran syntax __ % like dot . in c++</li><li>isend 必须使用wait 以为我们需要保证这个已经完成communicte isend + wait  &#x3D; send  sendres就是两个的简单集合</li><li>vscode 可以使用这个alt+left right 进行trace back and forth</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;GoMars&quot;&gt;&lt;a href=&quot;#GoMars&quot; class=&quot;headerlink&quot; title=&quot;GoMars&quot;&gt;&lt;/a&gt;GoMars&lt;/h1&gt;&lt;h2 id=&quot;Prerequisite&quot;&gt;&lt;a href=&quot;#Prerequisite&quot; class=&quot;head</summary>
      
    
    
    
    
    <category term="HPC" scheme="https://spikeihg.github.io/tags/HPC/"/>
    
  </entry>
  
  <entry>
    <title>6.S081</title>
    <link href="https://spikeihg.github.io/2024/02/29/6-S081/"/>
    <id>https://spikeihg.github.io/2024/02/29/6-S081/</id>
    <published>2024-02-29T11:32:09.000Z</published>
    <updated>2024-03-13T12:57:54.065Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Operating-System"><a href="#Operating-System" class="headerlink" title="Operating System"></a>Operating System</h1><ul><li><p>退出qemu ctrl x a . 注意还有一个点号！！！</p></li><li><p>在google中使用ctrl shift q 使用google scholar!。</p></li><li><p><font color=lavender>需要永久改变vim的配置 可以修改 ~&#x2F;.vimrc 文件</font></p></li><li><p><font color=orange>Spack 是一个包管理系统 主要用于很多科学专业的计算使用  $foo is a variable while $(foo) is a result of a command 变量名可以用{} 包围着 <br> 脚本中常见的if 中对文件使用的短句命令 -d foo 如果foo 存在且为目录 -e 如果存在 -f 如果存在且为普通文件  pushd 指令就是在程序执行的时候对所在的目录位置存在一个栈 ，pushd 后这个目录就位于top位置同时也变成现在的工作目录 功能和cd 类似的 但是在连续多步骤跳跃的时候很有用，这是cd可能需要多次连续使用</font></p></li><li><p>还有一招可以切换桌面 就是win 然后触摸板使用四个指同时滑动。</p></li><li><ul><li>一般來説，我们的这个page有一个高为的全为0  的 guard page in threre  这个保护页没有相应的PTE 所以一旦超过了这个范围就会导致一个page fault<ul><li>所以实际上这个映射是很复杂的 可以是多对多 也可以是多对一 一对多 所有的这些编程技巧都是通OS 实现的</li></ul></li><li>np 代表这个进程的数量</li><li>id 是在process mod 里面确定</li><li>ids ide  是在 mesh里初始化的 大小似乎就是点的个数</li></ul></li><li><p>学习了几个奇淫巧计 </p></li><li><p>tmux 打开窗口 然后可以Ctrl+b c create the new windows and the ctrl+b % to split the window 拆分窗口 ctrl+b “ 水平拆分 ctrl + b o 来回切换 注意这里的一个使用方法就是先点击 ctrl + b 然后在点击其余的按键</p></li><li><p><a class="link"   href="https://stackoverflow.com/questions/10534798/debugging-user-code-on-xv6-with-gdb" >这是xv6 gdb tutorial <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></li><li><p>首先咱们使用的命令是 gdb-multiarch 注意中间的横线一定不能少</p></li><li><p>然后就是上面的网址里写的</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Operating-System&quot;&gt;&lt;a href=&quot;#Operating-System&quot; class=&quot;headerlink&quot; title=&quot;Operating System&quot;&gt;&lt;/a&gt;Operating System&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;退出qem</summary>
      
    
    
    
    
    <category term="OS" scheme="https://spikeihg.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>New_Life</title>
    <link href="https://spikeihg.github.io/2024/01/01/New-Life/"/>
    <id>https://spikeihg.github.io/2024/01/01/New-Life/</id>
    <published>2024-01-01T04:35:55.000Z</published>
    <updated>2024-01-01T05:04:28.067Z</updated>
    
    <content type="html"><![CDATA[<p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/cowboy.gif"                                     ></p><h1 id="I-can-fix-that"><a href="#I-can-fix-that" class="headerlink" title="I can fix that"></a>I can fix that</h1><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ww.jpg"                                     ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img  
                     lazyload
                     src=&quot;/images/loading.svg&quot;
                     data-src=&quot;/../images/cowboy.gif&quot;</summary>
      
    
    
    
    
    <category term="自然" scheme="https://spikeihg.github.io/tags/%E8%87%AA%E7%84%B6/"/>
    
  </entry>
  
  <entry>
    <title>环形物语</title>
    <link href="https://spikeihg.github.io/2023/12/19/%E7%8E%AF%E5%BD%A2%E7%89%A9%E8%AF%AD/"/>
    <id>https://spikeihg.github.io/2023/12/19/%E7%8E%AF%E5%BD%A2%E7%89%A9%E8%AF%AD/</id>
    <published>2023-12-19T05:22:15.000Z</published>
    <updated>2024-02-28T08:31:33.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tales-from-the-Loop"><a href="#Tales-from-the-Loop" class="headerlink" title="Tales from  the Loop"></a><font color=deepskyblue>Tales from  the Loop</font></h1><h1 id="环形物语"><a href="#环形物语" class="headerlink" title="环形物语 "></a><font color=pink>环形物语</font> <br></h1><h2 id="环就在你心中"><a href="#环就在你心中" class="headerlink" title="环就在你心中"></a><font color=lightgreen>环就在你心中</font></h2><ul><li>一个假期，很多东西都忘记了，尤其是一些快捷键和命令之类的，以及blog的使用，这里就记下一些entries,在以后出现这种情况的时候可以快速复原。<ul><li>Blog : 首先powershell到博客文件夹， win x the i;  page up to find the cd command ; the hexo new to create  a md file with the title you give,hexo s just to start the local server, hexo g to generate your commits, hexo d to deploy you blog;</li><li>Google: 使用的一些东西 ctrl + tab tab之间进行切换  ctrl+ 数字 to jump to the given tab, ctrl + t create new tab, ctrl+ n create new window, alt+v translate the chosen word; </li><li>Windows: alt+tab switch the tasks; ctrl + win switch the background;</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Tales-from-the-Loop&quot;&gt;&lt;a href=&quot;#Tales-from-the-Loop&quot; class=&quot;headerlink&quot; title=&quot;Tales from  the Loop&quot;&gt;&lt;/a&gt;&lt;font color=deepskyblue&gt;Tale</summary>
      
    
    
    
    
    <category term="自然" scheme="https://spikeihg.github.io/tags/%E8%87%AA%E7%84%B6/"/>
    
  </entry>
  
  <entry>
    <title>APSP</title>
    <link href="https://spikeihg.github.io/2023/12/05/APSP/"/>
    <id>https://spikeihg.github.io/2023/12/05/APSP/</id>
    <published>2023-12-05T08:33:50.000Z</published>
    <updated>2023-12-13T08:36:45.462Z</updated>
    
    <content type="html"><![CDATA[<h1 id="APSP"><a href="#APSP" class="headerlink" title="APSP"></a><font color=deepskyblue>APSP</font></h1><ul><li><h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a><font color=pink>Prerequisites</font></h2><ul><li><font color=yellow><a class="link"   href="https://www.bilibili.com/video/BV1YW411h7Pk/?spm_id_from=333.337.search-card.all.click&vd_source=c8c7f6103570a31005f12d5a33a60b47" >morphine <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 先来一剂Green Day 牌吗啡！<br>在结尾处，准备总结一下实验的一些基本环境配置和有用链接以及FAQ留个之后看到这个网页以及遇到问题的人，所以如果是有问题需要解决可以先看看结尾。保证可以复现乐 : ) </font></li><li><a class="link"   href="https://cmake.org/cmake/help/latest/guide/tutorial/A%20Basic%20Starting%20Point.html" >Cmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><font color=yellow>熟悉cmake 的常见函数或命令以及了解下makefile 的原理 有点搞笑 我们的这个prefix 的路径似乎不能使用 ~ 而必须使用绝对路径 </font></li><li><a href="/doc/%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%AF%BC%E8%AE%BA.pdf">OpenMP</a><font color=yellow>OpenMP</font><ul><li><font color=lightgreen>首先，我们知道对于floyd算法的三层for循环中 ,最外层k 是无法并行化的，因为每一个k的路径比较依赖于已有的路径，需要顺序进行更新，但是内层i,j循环在src dest一定时，k 可以按照任何顺序选取所以是可并行的。因此private(i,j).</font></li><li><font color=lightgreen>OpenMP 原理 就是启用多线程，具体运行的时候可以跑在多核上，并行运算。底层就是pthread 实现的</font></li><li><font color=lightgreen>平衡负载，我采用的是dynamic ，不过可以多试试看看，static guide 都可以尝试，默认的也可以，感觉每次迭代的计算量似乎是随机的但是总体是均匀的 感觉static 应该就可以，dynamic 还是用在计算量会增加的比较好</font></li><li><font color=lightgreen>线程数的设置，过多会增大合并开销，同时还存在内存分配问题，降低效率，数量过少会导致并行度不够，根据我的猜想，看CUDA简介的经验，使用一个和迭代数以及某些硬件属性数的倍数或者因子书。32 64 之类的。问题不大，实践是检验真理的唯一方式，多试试就可以了，试了再来补充。</font></li><li><font color=lightgreen>编译器优化猜想，首先就是编译器可能帮我做了loop unrolling ,估计是fully peel the loop有可能。 然后就是寻址方式，依照CSAPP 上的，对于一个定长二维数组，确定一些基指针，然后使用定长进行改变。减少访存。然后就是使用局部变量来保存一些结果减少内存访问。同时也可能使用了一些向量化操作(AVX指令等等）。常熟计算(constant propgation)编译时计算，也就是constexpr。将小函数进行内联，但是本例中似乎不存在。</font></li><li><font color=lightgreen><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/omp.png"                                     ></font></li><li><font color=lightgreen>这个只是使用了最基本的for 内层循环并行，和负载动态分配</font></li><li><font color=lightgreen><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/simd_omp.png"                                     ></font></li><li><font color=lightgreen>这个比较客观，在第一次基础上使用了omp的 simd优化最内层循环。4096的加速比接近baseline的100倍，当然我这里选择的是64线程数 使用128线程差距不大。不过我个人感觉没有找到更好的方法进行线程数的调参。不知道有没有除了顺序试错外更高效准确的判断方法，还待我考察，欢迎学长指教。</font></li></ul></li><li><font color=yellow><a class="link"   href="https://arxiv.org/pdf/1811.01201.pdf" >AVX参考 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>avx优化</font><ul><li><font color=lightgreen>使用的是AVX512，用一个 mask store 来实现比较运算。</font></li></ul></li></ul></li><li><p><font color=pink><a class="link"   href="https://www.jstage.jst.go.jp/article/transinf/E95.D/12/E95.D_2759/_pdf" >BFW <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>(算法优化——Blocked Floyd Algorithm</font></p><ul><li><font color=lightgreen>查找了一下资料，似乎这个可以提高数据的局部性，当然需要设置好所分的矩阵块的大小，使处理一个数据块的工作集内存大概等于 L2 cache .但是感觉实现这个算法本身加速比不是很明显，然后分块的话额外内存开销较多。（还有就是懒:) 所以就没有进行应用。</font></li></ul></li><li><p><font color=pink>Pthread接口实现多线程</font></p><ul><li><font color=lightgreen>可以，今天用pthread把内层两个循环并行处理了一下，加速比大概500倍。跑4096的图用了13s左右，我自己设置的线程数为<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/Re1.png"                                     >这个时候文件夹还没改名，当然但就算法运行时间大概11s左右</font></li><li><font color=lightgreen>使用局部变量优化了一下 大概8s 多一点<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/Re3.png"                                     ></font></li></ul></li><li><p><font color=pink>AVX512改写内层循环 速度大概2s提升 4倍</font></p><ul><li><font color=lightgreen>不过这里我有一个问题，就是理论上直接来看，应该会提升16倍，实际上只提升4倍左右，我自己猜测的原因是缓存问题，由于嵌套循环，存取的时候空间局部性不是很好，等后面有时间profile 一下。</font></li><li><font color=lightgreen><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/unrool.png"                                     >循环展开64 后 线程数 90 接近突破2s</font></li><li><font color=lightgreen>记录下首次突破 2s 作了128的循环展开 然后将线程数调到了100<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/2s.png"                                     >后续测试感觉 64循环展开 和 128差不多了。感觉实际上我们的128循环展开可能效果还差一点，因为使每一个线程的工作负载变大了。</font></li><li><font color=lightgreen>感觉实在找不到什么可以优化的地方了（在我目前所学的知识范围内）<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/final.png"                                     >大概在1.85s左右 悲。有一个分块floyd算法，改善局部性，感觉就单独实现而言，确实可以通过减少工作集内存的范围来提高空间局部性。但是因为涉及到要重写pthread,感觉反而会增加线程创建的开销。因为需要不断迭代子方块，然后进行pthread_create和pthread_join。</font></li><li><font color=lightgreen>本来想学一学使用 vtune 来剖析一下，似乎集群没有装，然后数据scp 命令没有使用权限，所以没有profile很多对性能的猜测都是自己的直觉 乐！</font></li><li><font color=lightgreen>至于GPU的算法，看了一下，似乎没有看到集群有装CUDA，所以没打算写，看后面有没有时间参考下资料看一看。</font></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;APSP&quot;&gt;&lt;a href=&quot;#APSP&quot; class=&quot;headerlink&quot; title=&quot;APSP&quot;&gt;&lt;/a&gt;&lt;font color=deepskyblue&gt;APSP&lt;/font&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;h2 id=&quot;Prerequisites&quot;&gt;&lt;a</summary>
      
    
    
    
    
    <category term="hpc" scheme="https://spikeihg.github.io/tags/hpc/"/>
    
  </entry>
  
  <entry>
    <title>DL</title>
    <link href="https://spikeihg.github.io/2023/11/23/DL/"/>
    <id>https://spikeihg.github.io/2023/11/23/DL/</id>
    <published>2023-11-23T11:24:27.000Z</published>
    <updated>2023-12-05T15:35:17.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Deep-learning-premier"><a href="#Deep-learning-premier" class="headerlink" title="Deep learning premier"></a><font color=pink>Deep learning premier</font></h2><p><font color =violet>志を受け継ぎ世界と戦う</font></p><ul><li><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a><font color=lightgreen>Transformer</font></h2><p>transformer是什么？变形金刚！！！ 好吧transformer 是用来解决seq2seq的一个模型。 seq2seq是一种模式，一些常见的情形：翻译，听译，语音辨识，听译 男泵 万恶之源 硬train一发 chatbot 之类的也是</p><p>BOS</p><ul><li><p>NLP QA模式 问题回答的一种模式</p></li><li><p>multi-label 就是每一个输入对象可能身上有多个标签</p></li><li><p>transformer 就是求解s2s的一个模型 encoder 和 decoder</p></li><li><p>residual connection 这个是与self attention 不一样的地方把input 和 output加起来</p></li><li><p>为什么能够应对seq2seq的情况</p><p>输入有两个部分 一部分来则于自己之前的输出</p><p>masked -attention 为什么需要</p><p>单纯看自己的输入作为输出的时候不可能停止下来，机，器，学。习。惯…… 首先我们需要准备以恶搞special toke as end(断) 所以原理就是让机器学习断，在该停止时候最大的概率输出end</p><p>上面是对于AT NAT是同时产生所有的输出 解决停止问题 有两个，第一个单独训练一个classifier来判断长度，方法二，传入很多begin token.忽略end 后的 输出 NAT 更好的并行化，可以控制长度 但是效果很难达到AT multi-modality</p><p>decoder 和 encoder的连接依靠一个叫做 cross-attention 的操作完成的就是 decoder 产生的向量q然后对每一个encoder的output k做kq，然后得到的新的v作为input丢到fc进行之后操作</p><p>train的时候采用分类的视角 计算向量之间的cross-entrophy 并且在训练情况下，我们给decoder的是正确的答案 就是一个监督 tearcher forcing </p><p>训练的一些 tips copy mechanism 例如chat-bot 将一些从来没有见过的词汇 直接进行复制 例如做摘要的时候 pointer network</p><p>TTS 语音合成 guide attention 就是规定 attention的顺序 有固定的过程 需要提前分享任务的特征monotonic attention</p><p>观察确定 我们的encoder 就是输出简单的数据 作为中间向量</p><p><font color=yellow>beam search</font> greedy path可能存在问题 局部最优不代表全局最优 类似于老师讲的王者问题 加入随机 decoder加一点 noise</p><p><font color=pink>BLEU score 用来检测inference 的指标但是训练的时候使用的是cross -entrophy 这两个没有关联的，没有相关性的blet score无法微分 一种策略使用 rl reinforcing learning reward与 agent来硬train一发</font></p><p><font color=cornsilk>在训练的时候加入一些错误的情况，scheduled sampling 也很直觉啊，面对错误的时候得到正确的这样学习应对错误的能力</font></p></li></ul></li><li><h2 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a><font color=deepskyblue>self-attention</font></h2><ul><li>q,k 矩阵学习 multi-head 就是分出多个 q 矩阵 然后得到bi,j 然后再处理成一个 positional embding , hand-crafted 目前的 目前是一个全新的领域 也可以学习。 self-attention 之间是没有位置关系的，然后q k 也不一定需要包含整个窗口</li></ul></li><li><h2 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a><font color=salmon>Batch normalization</font></h2><p>layer norm 是对同一个feature(sample)不同的dim 进行计算 mean和 deviation 而 batch norm 是对所有不同的feature 的同一个dim 进行处理</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/transf.png"                                     ></p><ul><li>position coding 位置资讯 </li><li><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/bert.png"                                     ></li></ul></li><li><p>实际设计中还可以在顺序上进行变换 上述大概就是encode 结构</p></li><li><p>decoder</p><ul><li>bos （begin special token）特殊的符号 标记开始</li><li>masked self- attention 和通常的attention 有一些区别</li><li>为什么 因为decoder是一个一个产生的 在产生前面的输出时，后面的右边的输出还没有产生 无法考虑</li><li>autoregressive</li><li>自己不断运作，输出再次作为输入然后一直运行  存在停止的问题 方法就是设置另一个token 有时候与begin其实是同一个 实际实现可能是一个one-hot 向量，end也是自己产生的男泵</li><li>NAT non-autoregressive</li></ul></li><li><h2 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a><font color=white>pytorch</font></h2><ul><li><p>总体流程就是，先定义我们的数据， dataset可以理解为存储我们的数据，feature 和 label ，然后dataloader 以我们想要的方式加载数据，自定义操作，包括batch ,还有 transform 等等。</p></li><li><p>然后就是定义 目标函数 loss ，以及一个优化器 optimizer ，有了之后定义 响应的train 和 test 函数 ，最后还有对模型的保存以及调用 和实际运用。</p></li><li><p>tensor (array)统一的却应用广泛的数据结构 ，就是一个高维数组，最外面的维度为dim&#x3D;0 注意顺序 然后基本上有外面可能用到的所有操作，只需要用时自己去找api 查资料就可以了。</p></li><li><p>dataloader &amp; dataset</p><ul><li>torch.utils.data.dataset torch.utils.data.dataloader 两个基本的提供的模块除此之外很多专门领域的domain-specified 的库都有自己的相关的。 注意一般来说,然后从我们的视角来看，就是一个数组 索引得到feature and label 同时得到。a,b&#x3D;dataset[index]大概这样，然后label 一般存在一个csv文件（逗号分隔文件里面）然后就自定义__init—— len getitem三个函数init 的时候传入的 是一个annotation_file 和 dir 两个都是字符串，然后两个transform 函数一个transform 一个 target_transform</li><li>pandas 是一个数据处理  比如读取csv_file 之类 os 就是处理字符串之类的</li><li>dataloader 的每一次迭代返回两个tensor 对应feature和label</li><li>transform modify featu target_transform modify label<ul><li>常见的totensor 就是实现normalize 并且使得元素在0-1 之间。 vector lambda就是自定义操作</li></ul></li></ul></li><li><p>build the network</p><ul><li>torch.nn 所有存在的neuralnet的父类。 module其实就可以理解为layer 一个神经网络就可以理解为 a module itself that consists of other modules(layers) from torch import nn</li><li>第一步先check一下可不可以用硬件加速</li><li>然后继承 nn.Module 然后定义两个东西 init 和 forward方法</li><li>我们来break down and see every module拆解看看每一层<ul><li>flatten 在图形里面用来将一个image 矩阵转换为一个一维数组</li><li>linear 层就是进行一个线性转换 我们需要预先输入一个weigth 和 bias参数 然后对feature 进行变换</li><li><font color=pink>这里一个额外的补充知识点 就是call 特殊方法可以实现将类作为i函数调用 这就是为什么我们可以调用model，将数据作为参数输入进去 linear其实就是继承了nn.Module</font></li><li>妈的，我逐渐反应过来了，linear层里面的bias ,weight都是默认输出话，随机的其实，因为这个是我们要学习的参数，所以随机初始化就可以了。不需要什么预置输入</li><li>这里提前所以个东西 Relu 可以解决sigmoid 和tanh的过饱和问题缓解过拟合问题 也是目前默认激活函数</li><li>flatten默认改变的是最里面的层 没有改变channel 和batchsize</li><li>nn.sequential 就是一个layer的顺序容器 其实经过一个sequential 我们就可以发现输出了y 相当于fully connected network 啊男泵</li><li>nn.softmax 如果分类还需要过一层 注意通常要指定softmax操作的维度</li><li>parameter() named_parameters()这两个方法可以让神经网络追踪传入的参数哦从而进行学习</li><li>终于逐渐理解了</li></ul></li></ul></li><li><p>automatic differentiation</p><ul><li><p>关于tensor 的矩阵乘法 要了解到tensor最后面的参数一定是列向量 这个有点差异</p></li><li><p>parameter 就是我们需要进行optimize的 weight bias 都是。对于这些参数，我们需要优化，所以我们需要预先设定require_gradient ,默认是false</p><ul><li><p>然后调用Function 类，这个在每一个tensort 的 grad.fn 属性里存这一个指针，表示该tensor所使用的反向传播计算时的函数</p></li><li><p>在tensor的grad 里面维护的是计算得到的梯度值</p></li><li><p><font color=orange>所以现在我们可以这样理解forward就是利用model来进行计算，backword就是train，所以后面我们训练完成的时候，需要使用 with torch.no_grad()的方法</font></p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/DAG.png"                                     ></p></li></ul><p>  现在来审视这个 DAG leaves is input tensor root is output tensor and the node is function !!!!!</p><ul><li>然后实际的是实现中我们使用了雅各布矩阵直接做矩阵乘法！！！</li></ul></li></ul></li><li><p><font color=violet>Optimizing model</font></p><ul><li>在上面的过程我们可以明白了，forward其实就是调用预测时候的算法，所以实际上就是直接调用我们的init 里面的层 然后返回就可以了</li><li><font color=cyan>在这里我们区分一下parameter ,就是在里面起作用的东西，hyperparameter 更像是一些设置配置参数 例如 learning rate ,batch size ,number of epochs</font><ul><li>loss function 。 对于回归问题我们通常使用的是MSELoss, 对于classification 我们通常使用的 是 negative  log likelihood NLLLoss 然后nn.crossentropyloss 就是 logsoftmax和NLLLoss的结合</li><li>我们前面学的adam rmsprop sgd 其实就是不同的optimizer 也就是minimize的时候使用的算法</li><li>实际运行的时候有三个步骤<ul><li>第一步就是先显式置零，同时自动累计grad,以免没重复加</li><li>第二步就是运行反向传播算法</li><li>第三步 调用.step()方法进行更新</li></ul></li><li>最后就是进行实现两个loop 一个train loop 一个 test loop</li></ul></li><li><font color=pink>Save and load the model</font><ul><li>组后要进行保存和加载的化调用响应的方法即可 ，然后注意两个东西就是.eavl() 模式的切换，记住这个是避免dropout和batch normalization 的一个东西</li></ul></li></ul></li><li><h2 id="computational-graph"><a href="#computational-graph" class="headerlink" title="computational graph"></a><font color=salmon>computational graph</font></h2><ul><li><p>反向传播</p><p>前向传播和反向传播 forward and backward torch的抽象 forward 可以理解为求值 从input 到output 从leaf到root 反向传播就是求误差，根据链式法则求取偏导然后更新参数进行optimize。</p></li><li><p>torch的实际实现过程</p><p>根据我们对neuralnet 的定义  一个sequential 里面有很多layer，然后forward就是调用这个module ,在进行forward pass的时候会进行两件事情，第一件事就是按照要求计算得到output tensor第二件事就是建立其DAG，每个结点就是对应的求导函数，在后续的backward pass中调用进行求导</p><p> what you run is what you differentiate.</p><ul><li>tensor 需要保存，用来求导</li><li>对于数学上不可求导的函数或者是未定义情况有指定的数学方式来处理</li><li>先要阻止gradient 可以更改text manager mode 以及.eval(),同时要想控制子图subgraph的性质 可以对单个tensor 调用 require_grad</li><li>torch.nn 中parameter默认要求导，中间变量都会求导</li><li>现在终于懂了</li><li>lossfunction 进行 backward()相当宇求梯度然后得到grad值，optimizer 则是根据不同的类型操作 grad 进行更新所有  parameter  .step()就是进行一步 。 .zero_grad()就是重置tensor</li></ul></li><li><p>梯度消失和爆炸 的原因</p><p>我们在计算梯度的时候采用的是反向传播求取雅各布矩阵，由于很多hidden layer都会采用一些激活函数对于sigmoid而言，其倒数最大值为0.25 如果乘以w 后得到的积仍然小于1 如果很多小于1累计起来可能造成靠近输入层的参数更新极为缓慢，当然输出层的影响较小，爆炸则是产生NaN 或者不稳定。</p></li></ul></li></ul></li><li><h2 id="transformer-is-all-you-need"><a href="#transformer-is-all-you-need" class="headerlink" title="transformer is all you need"></a><font color=deepskyblue>transformer is all you need</font></h2><ul><li><font color=yellow>正向的 rnn 。 双向的rnn 可以正反同时读取我们的，</font></li><li>LSTM 关键四个们 标量也是用来学习的 每个单元可以用来替代之前的neuron 然后只是输入需要四倍，因为三个们和一个输入 。使用的是sigmoid 函数表示打开的程度。实际的模型还会在输入中参考中间步骤的输入</li><li>BPTT learning train  的 方法。考虑时间的关系。</li><li>train的问题 error surface存在很平坦到很陡峭的分界限，所以存在参数的抖动。 clipping 解决方案，就是为gradient 做一个上界，如果超过就直接等于。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Deep-learning-premier&quot;&gt;&lt;a href=&quot;#Deep-learning-premier&quot; class=&quot;headerlink&quot; title=&quot;Deep learning premier&quot;&gt;&lt;/a&gt;&lt;font color=pink&gt;Deep l</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="https://spikeihg.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Winter</title>
    <link href="https://spikeihg.github.io/2023/11/21/Winter/"/>
    <id>https://spikeihg.github.io/2023/11/21/Winter/</id>
    <published>2023-11-21T08:00:38.000Z</published>
    <updated>2023-11-22T08:53:33.353Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Winter"><a href="#Winter" class="headerlink" title="Winter"></a><font color=violet>Winter</font></h2><blockquote><p>我是未来世界唯一的程序员。这是一条来自未来的讯息。在我的时代，支配世界的算法被我洞晓。过去的人啦，想要改变未来吗？去探索吧，这个世界背后运行的真理！—— 2079 . 12 . 24 </p></blockquote><p><strong><font color=deepskyblue>世界の仕組みについての真実を理解しました</font></strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Winter&quot;&gt;&lt;a href=&quot;#Winter&quot; class=&quot;headerlink&quot; title=&quot;Winter&quot;&gt;&lt;/a&gt;&lt;font color=violet&gt;Winter&lt;/font&gt;&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;我是未来世界唯一的程序员。这是</summary>
      
    
    
    
    
    <category term="自然" scheme="https://spikeihg.github.io/tags/%E8%87%AA%E7%84%B6/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm</title>
    <link href="https://spikeihg.github.io/2023/11/02/Algorithm/"/>
    <id>https://spikeihg.github.io/2023/11/02/Algorithm/</id>
    <published>2023-11-02T02:11:09.000Z</published>
    <updated>2023-11-21T06:38:30.103Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a><font color=yellow>Algorithm</font></h1><ul><li><strong><font color=seagreen>最近点对问题</font></strong><ul><li><font color=pink>分治法求解 垂直线分割 实际使用时可以对应实际的问题进行优化 比如使用一个 strip  然后可以在递归的最底层加入一个全局的区间值的判断 双重循环 但是每一层都是O(n^1&#x2F;2)判断方法是否存在在特殊情况失效 例如几乎垂直或者水平的点对。所以可以单独的进行筛选 类似机器学习的算法的改进 多个维度通道 简化的一些思想 </font></li><li><font color=pink>对称性思想 每一个维度都是一样的</font></li><li><font color=pink>建表  对于频繁使用的信息进行见表索引检索哈希码 向量 量化处理</font></li><li><font color=pink>曼哈顿距离</font></li></ul></li><li><strong><font color=seagreen>概率分析与随机算法</font></strong><ul><li><font color=pink></font></li></ul></li><li><strong><font color=seagreen>正太分布问题思考</font></strong><ul><li><font color=pink>解决一种问题 就是关于某个中心点对称任何维度的可能性相同。 同时随着偏离中心概率减小 关键就在于与角度无关 非常的厉害</font></li></ul></li><li><strong><font color=seagreen>随机问题</font></strong><ul><li><font color=pink>随机生成一个数组的方法 一 可以为每个元素生成一个优先级 然后根据rank 进行排序</font></li></ul></li><li><strong><font color=seagreen>排队论</font></strong><ul><li><font color=pink>所有人排在一起，那个窗口空去哪个</font></li></ul></li><li><strong><font color=seagreen>同时获得最大值和最小值</font></strong><ul><li><font color=pink>同时维护两个值比较 n-1</font></li></ul></li><li><strong><font color=seagreen>活动安排问题</font></strong><ul><li><font color=pink>选择一个拥有最多活动的集合 集合的实践区间不存在重叠。使用贪婪算法，按照结束时间排序，然后每次都加入最早结束的时间 最核心的地方就是按结束时间思考，存在多解问题，原因在于开始阶段。</font></li></ul></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li><li><strong><font color=seagreen></font></strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Algorithm&quot;&gt;&lt;a href=&quot;#Algorithm&quot; class=&quot;headerlink&quot; title=&quot;Algorithm&quot;&gt;&lt;/a&gt;&lt;font color=yellow&gt;Algorithm&lt;/font&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;f</summary>
      
    
    
    
    
    <category term="Algorithm" scheme="https://spikeihg.github.io/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>佩索呀</title>
    <link href="https://spikeihg.github.io/2023/10/29/%E4%BD%A9%E7%B4%A2%E5%91%80/"/>
    <id>https://spikeihg.github.io/2023/10/29/%E4%BD%A9%E7%B4%A2%E5%91%80/</id>
    <published>2023-10-29T08:04:14.000Z</published>
    <updated>2024-03-13T12:44:03.438Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Darling-I-‘m-getting-older-亲爱的，我原来也会变老"><a href="#Darling-I-‘m-getting-older-亲爱的，我原来也会变老" class="headerlink" title="Darling . I ‘m getting older. (亲爱的，我原来也会变老)"></a>Darling . I ‘m getting older. (亲爱的，我原来也会变老)</h3><ul><li><p>Everyday poetry.</p></li><li><p><a class="link"   href="https://poets.us20.list-manage.com/track/click?u=e329a0cb6f08842f08a05d822&id=50cda6fc43&e=dce612a19d" >Sippokni Sia <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><p><a href="https://poets.us20.list-manage.com/track/click?u=e329a0cb6f08842f08a05d822&id=a7f92fa877&e=dce612a19d"><strong>Winnie Lewis Gravitt</strong></a></p><p>I am old, Sippokni sia. Before my eyes run many years, Like panting runners in a race. Like a weary runner, the years lag; Eyes grow dim, blind with wood smoke; A handkerchief binds my head, For I am old. Sippokni sia.Hands, once quick to weave and spin; Strong to fan the tanchi; Fingers patient to shape dirt bowls; Loving to sew hunting shirt; Now, like oak twigs twisted. I sit and rock my grandson. I am old. Sippokni sia.Feet swift as wind o’er young cane shoots; Like stirring leaves in ta falla dance; Slim like rabbits in leather shoes; Now moves like winter snows, Like melting snows on the Cavanaugh. In the door I sit, my feet in spring water. I am old. Sippokni sia.Black like crow’s feather, my hair. Long and straight like hanging rope; My people proud and young. Now like hickory ashes in my hair, Like ashes of old camp fire in rain. Much civilization bow my people; Sorrow, grief and trouble sit like blackbirds on fence. I am old. Sippokni sia hoke.</p><ul><li>我不知道人们所说的衰老是什么样子的，也许是透过镜子发现曾经的皮肤已经松弛下垂，也许当他们发现他们跑不过一个最小的孩子，但我感觉衰老是发生在一瞬间，仅仅一瞬间，就像过了一辈子，只是从前漫长的岁月从未被老去的忧伤笼罩，就像山顶的雾终于散去，时间失去了从前的神秘。</li><li>告别，寻找告别</li><li>春天总是一去不返</li><li>无法思考，无法摆脱，3点，神秘力量，是她吗……</li></ul></li><li><p>Amy Lowell</p><ul><li><p>A enthralling person with all her persistence, intelligence , energy and fecundity.  “ The god made me  a business woman , but I made myself a poet .”</p></li><li><h1 id="The-Garden-by-Moonlight"><a href="#The-Garden-by-Moonlight" class="headerlink" title="The Garden by Moonlight"></a>The Garden by Moonlight</h1><p>BY <a class="link"   href="https://www.poetryfoundation.org/poets/amy-lowell" >AMY LOWELL <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><p>A black cat among roses,</p><p>Phlox, lilac-misted under a first-quarter moon,</p><p>The sweet smells of heliotrope and night-scented stock.</p><p>The garden is very still,  </p><p>It is dazed with moonlight,</p><p>Contented with perfume,</p><p>Dreaming the opium dreams of its folded poppies.</p><p>Firefly lights open and vanish  </p><p>High as the tip buds of the golden glow</p><p>Low as the sweet alyssum flowers at my feet.</p><p>Moon-shimmer on leaves and trellises,</p><p>Moon-spikes shafting through the snow ball bush.  </p><p>Only the little faces of the ladies’ delight are alert and staring,</p><p>Only the cat, padding between the roses,</p><p>Shakes a branch and breaks the chequered pattern</p><p>As water is broken by the falling of a leaf.</p><p>Then you come,</p><p>And you are quiet like the garden,</p><p>And white like the alyssum flowers,  </p><p>And beautiful as the silent sparks of the fireflies.</p><p>Ah, Beloved, do you see those orange lilies?</p><p>They knew my mother,</p><p>But who belonging to me will they know</p><p>When I am gone.</p></li></ul></li><li><p>A imagist poet as Pound .  Some intellectual game when you read some volume of her you just feel like .</p></li></ul><h1 id="Sylvia-Plath"><a href="#Sylvia-Plath" class="headerlink" title="Sylvia Plath"></a>Sylvia Plath</h1><ul><li>At her most articulate, meditating on the nature of poetic inspiration, [Plath] is a controlled voice for cynicism, plainly delineating the boundaries of hope and reality. At her brutal best—and Plath is a brutal poet—she taps a source of power that transforms her poetic voice into a raving avenger of womanhood and innocence.</li></ul><h2 id="When-I-am-dead-my-dearest"><a href="#When-I-am-dead-my-dearest" class="headerlink" title="When I am dead , my dearest."></a>When I am dead , my dearest.</h2><p>When I am dead, my dearest,</p><p>Sing no sad songs for me;</p><p>Plant thou no roses at my head,</p><p>Nor shady cypress tree:</p><p>Be the green grass above me</p><p>With showers and dewdrops wet;</p><p>And if thou wilt, remember,</p><p>And if thou wilt, forget.</p><p>I shall not see the shadows,</p><p>I shall not feel the rain;</p><p>I shall not hear the nightingale</p><p>Sing on, as if in pain:</p><p>And dreaming through the twilight</p><p>That doth not rise nor set,</p><p>Haply I may remember,</p><p>And haply may forget.</p><ul><li><p>徐志摩的翻译也很美，似乎也是他有首诗的foutainhead.</p></li><li><p>Not a red rose or a satin heart.</p></li></ul><h2 id="Valentine"><a href="#Valentine" class="headerlink" title="Valentine"></a>Valentine</h2><p>I give you an onion.<br>It is a moon wrapped in brown paper.<br>It promises light<br>like the careful undressing of love.</p><p>Here.<br>It will blind you with tears<br>like a lover.<br>It will make your reflection<br>a wobbling photo of grief.</p><p>I am trying to be truthful.</p><p>Not a cute card or a kissogram.</p><p>I give you an onion.<br>Its fierce kiss will stay on your lips,<br>possessive and faithful<br>as we are,<br>for as long as we are.</p><p>Take it.<br>Its platinum loops shrink to a wedding ring,<br>if you like.<br>Lethal.<br>Its scent will cling to your fingers,<br>cling to your knife.</p><h1 id="The-More-Loving-One"><a href="#The-More-Loving-One" class="headerlink" title="The More Loving One"></a>The More Loving One</h1><p>BY <a class="link"   href="https://www.poetryfoundation.org/poets/w-h-auden" >W. H. AUDEN <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><p>Looking up at the stars, I know quite well</p><p>That, for all they care, I can go to hell,</p><p>But on earth indifference is the least</p><p>We have to dread from man or beast.</p><p>How should we like it were stars to burn</p><p>With a passion for us we could not return?</p><p>If equally affection cannot be,</p><p>Let the more loving one be me.</p><p>Admirer as I think I am</p><p>Of stars that do not give a damn,</p><p>I cannot, now I see them, say</p><p>I missed one terribly all day.</p><p>Were all stars to disappear or die,</p><p>I should learn to look at an empty sky</p><p>And feel its total dark sublime</p><p>Though this might take me a little time.</p><p>September 1957</p><ul><li><p>今天读到的一首灵动的诗 引用的那篇文章也写得很好</p></li><li><p><font color=salmon>今天读完了那篇文章，很有趣，文笔也很优美，提到了很多有趣的idea，一个有趣的失恋者，哈哈，the more loving one .<a class="link"   href="https://www.poetryfoundation.org/articles/162120/but-there-are-other-geometries" > <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 在另一个世界 会有不一样的几何，有不一样的命运，也许我们就能够在理智与爱的坐标上相遇</font></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Darling-I-‘m-getting-older-亲爱的，我原来也会变老&quot;&gt;&lt;a href=&quot;#Darling-I-‘m-getting-older-亲爱的，我原来也会变老&quot; class=&quot;headerlink&quot; title=&quot;Darling . I ‘m g</summary>
      
    
    
    
    
    <category term="自然" scheme="https://spikeihg.github.io/tags/%E8%87%AA%E7%84%B6/"/>
    
  </entry>
  
  <entry>
    <title>CUDA</title>
    <link href="https://spikeihg.github.io/2023/10/24/CUDA/"/>
    <id>https://spikeihg.github.io/2023/10/24/CUDA/</id>
    <published>2023-10-24T06:20:19.000Z</published>
    <updated>2023-11-06T09:00:06.924Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CUDA-amp-Algorithm"><a href="#CUDA-amp-Algorithm" class="headerlink" title="CUDA&amp;Algorithm"></a><strong><font color=darkturquoise>CUDA&amp;Algorithm</font></strong></h1><ul><li><h2 id="Prelace"><a href="#Prelace" class="headerlink" title="Prelace"></a><font color=pink>Prelace</font></h2><p><strong><font color=mediumaquamarine>希望通过CUDA走进计算的前言，并且加深我对计算机体系结构的认知。同时从另一条路走进我们的machine learning 与 deep learning.同时也在这里写下一些算法的学习知识。</font></strong></p></li><li><h2 id="F-amp-Q"><a href="#F-amp-Q" class="headerlink" title="F&amp;Q"></a><font color=DarkSeagreen>F&amp;Q</font></h2><ul><li><p>内存布局具体硬件实现忘了，忘了栈实际上是在cache还是memory里</p></li><li><p>nvidia-smi 才是查看设别的指令 nvidia-smi -q 不错 </p></li><li><p>nvprof 已经弃用了 ncu（nsight-compute) 现在是profiler</p></li><li><p>nsight-compute 需要 全局安装 sudo apt install -y 选项<a class="link"   href="https://developer.nvidia.com/nvidia-development-tools-solutions-err_nvgpuctrperm-permission-issue-performance-counters#AllUsersTag" >issue <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></li><li><p><font color=pink>driver 是一个硬件用来显示的   tookit就是一个集合 有些下载method可以同时下载适配的 driver 总结就是除了会安装还要学会卸载</font></p></li><li><p>These instructions must be used if you are installing in a WSL environment. Do not use the Ubuntu instructions in this case; it is important to not install the <code>cuda-drivers</code> packages within the WSL environment. <font color=red>乐死</font></p></li><li><p>Installation using RPM or Debian packages interfaces with your system’s package management system. When using RPM or Debian local repo installers, the downloaded package contains a repository snapshot stored on the local filesystem in &#x2F;var&#x2F;. Such a package only informs the package manager where to find the actual installation packages, but will not install them.</p><p>If the online network repository is enabled, RPM or Debian packages will be automatically downloaded at installation time using the package manager: apt-get, dnf, yum, or zypper.</p></li><li><p>安装是很复杂的 wsl有单独的教程 然后就是 有 post-installation mandatory actions !!</p></li><li><p>The <code>PATH</code> variable needs to include <code>export PATH=/usr/local/cuda-12./bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</code>. Nsight Compute has moved to <code>/opt/nvidia/nsight-compute/</code> only in rpm&#x2F;deb installation method. When using <code>.run</code> installer it is still located under <code>/usr/local/cuda-12.2/</code>.<font color=cyan>记住这个路径问题 在opt里面</font></p></li><li><p><font color=pink>妈妈我终于解决这个问题了 就是我在安装后没有设置环境变量 啊啊啊啊啊啊 男泵</font></p></li><li><p><a class="link"   href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions" >今后还可能出现的 问题 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></li><li><p>开始在vscode 里面进行配置 nsight debug</p></li><li><p>ctrl + space </p></li><li><p>命令面板很好用目前看来 ctrl shift + p</p><h2 id="我修改了提示-ctrl-t-s-好有用啊-还有就是控制面板太好用了有很多提示键-然后-task-也可以在里面选择生成"><a href="#我修改了提示-ctrl-t-s-好有用啊-还有就是控制面板太好用了有很多提示键-然后-task-也可以在里面选择生成" class="headerlink" title="我修改了提示 ctrl + t + s 好有用啊 还有就是控制面板太好用了有很多提示键 然后 task 也可以在里面选择生成"></a>我修改了提示 ctrl + t + s 好有用啊 还有就是控制面板太好用了有很多提示键 然后 task 也可以在里面选择生成</h2><ul><li><strong>[launch attach&amp; launch.json entry](<a class="link"   href="https://code.visualstudio.com/docs/editor/debugging" >Debugging in Visual Studio Code <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>)</strong></li></ul></li><li><p>dropdown configuration 就是下落的可以滑动的竖直设置栏</p></li><li><h3 id="预定义变量"><a href="#预定义变量" class="headerlink" title="预定义变量"></a><a class="link"   href="https://code.visualstudio.com/docs/editor/variables-reference" >预定义变量 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h3></li><li><h3 id="最新发现-ctrl-alt-n-code-runner-似乎无所不能-但是不能调试只是"><a href="#最新发现-ctrl-alt-n-code-runner-似乎无所不能-但是不能调试只是" class="headerlink" title="最新发现 ctrl alt n code runner 似乎无所不能 但是不能调试只是"></a>最新发现 ctrl alt n code runner 似乎无所不能 但是不能调试只是</h3></li><li><p>program 就是 要debug的文件</p><ul><li><p><font color=gold>注意这个launch 是调试 要先生成可执行文件 也就是task 先配置的是task 然后是 launch.json</font></p></li><li><p><font color=green>重点出现了 发现可能的解决方案 就是prelaunch task 原来之前的是task 在debug后运行或者至少同时</font></p></li><li><p><font color=yellow>原来c_cpp_pr 是C++插件的配置文件不会影响</font></p></li></ul></li></ul></li><li><h2 id="Heterogeneous-Computing"><a href="#Heterogeneous-Computing" class="headerlink" title="Heterogeneous Computing"></a><strong><font color=tan>Heterogeneous Computing</font></strong></h2><ul><li><p><font color=teal>host指cpu，host codes run in CPU ,CPU code is responsible for managing the code and environment and device code running in GPUs.</font></p></li><li><p><font color=cornsilk>common GPU architectur GeForce Tesla and Fermi in Tesla  Tesla professional hpc. GeForce consumer GPUs</font></p></li><li><p><font color =cornsilk>two metrics to discribe the GPU compute capability .the core no. and the memory</font></p></li><li><p><font color =cornsilk>互补的 CPU 逻辑复杂 擅长分支预测控制流切换 GPU 擅长大量数据 简单控制 并行计算 Threads of CPU are heavyweighted 上下文切换开销大。 GPU就是相对轻量级 的</font></p></li><li><p><font color =cornsilk>CUDA driver API and CUDA runtime API 我们一般使用 runtime API cuda codes 包含两个部分 一个是host code 另一个是device code </font></p></li><li><p><font color =cornsilk>kernels 就是device code 里的并行函数由 nvcc 编译 nvcc 会区分host code and device code 然后就是完全分开执行 good<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/cucode.png"                                     ></font></p></li><li><p><font color =cornsilk>hello from GPU GPU program structure 5 steps 分配显存 加载数据 invoke kernel 返回数据 销毁显存</font></p></li><li><p><font color =cornsilk>locality temporal locality and spatial locality 这是编写cpu程序注意的 而GPU 将存储架构和线程结构都展示给程序员</font></p></li><li><p><font color =cornsilk>three key abstractions 三个关键抽象对于GPU 1. hierarchy of thread groups 2. hierarchy of memory 3. barrier synchronization </font></p></li><li><p><font color=cornsilk><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/nvcc.png"                                     >nvcc 支持的文件后缀 .c 普通的是可以编译的</font></p></li><li><p><font color=cornsilk>programming model 其实就是 抽象 通过使用compiler and library &amp; OS 对hardware architecture 的抽象   scalability 可拓展性</font></p></li><li><p><font color=cornsilk>Host CPU and its memory ; Device : GPUs and its memory eg h_ for host m; d_ for device space</font></p></li><li><p><font color=cornsilk>Kernel 即跑在GPU 的codes我们可以看作是一个普通函数 实际上 GPU将其分配在多个线程上同时运行 ，当kernel运行后控制会立马交还给cpu以开始其他工作 异步工作。serial code 串行码 complemented by parallel code</font></p><div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Memory management */</span></span><br><span class="line"><span class="built_in">malloc</span>(); -&gt; <span class="built_in">cudaMalloc</span>();</span><br><span class="line"><span class="built_in">memcpy</span>(); -&gt; <span class="built_in">cudaMemcpy</span>();</span><br><span class="line"><span class="built_in">cudaMemset</span>();</span><br><span class="line"><span class="built_in">cudaFree</span>();<span class="comment">// all in device memory which is seperated from host memery!!</span></span><br><span class="line"><span class="comment">// the signature of the func</span></span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaMalloc</span><span class="params">(<span class="type">void</span>**devPtr,<span class="type">size_t</span> size)</span></span>;<span class="comment">// the pointer is returned in the devPtr</span></span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaMemcpy</span> <span class="params">( <span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span>* src, <span class="type">size_t</span> count,cudaMemcpyKind kind )</span> <span class="comment">// the kind takes one of the following types cudaMemcpyHostToHost --HostToDevice --Dev2Dev D2H this func 是同步的 host 会阻塞知道完成</span></span></span><br><span class="line"><span class="function"><span class="comment">// cudaError_t enumerated type include cudaSuccess .eg </span></span></span><br><span class="line"><span class="function">    <span class="type">char</span>*<span class="title">cudaGetErrorString</span><span class="params">(cudaError_t error)</span></span>;</span><br></pre></td></tr></table></figure></div></li><li><p><font color=cornsilk>Global memory and shared memory in device just like memory and cache in CPU 前面的分配的函数都是在global memory 里面就像我们的malloc一样 目前我们所知道的由于这样内存分类 对应的指针是不能类型转换的，只能用cudaMemcpy来完成转移 后期由unified memory</font></p></li><li><p><font color=cornsilk><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/bg.png"                                     >通常而言 grid是二维 block是三维  blockDim gridDim dim3 type 没有初始化的filed自动为1</font></p></li><li><p><font color=cornsilk>P88 warp执行模型 32 个thread 硬件层面都会变成 warp 然后分散在SM上执行 之所以可以是主要是内存资源决定的 32 cores是共享的 前面说到多个warp scheduler 调度将warp的一个指令放到16core的一个组合上运行 其中register file 决定了warp 数量 shared memory 决定sm的block数量 然后warp切换上下文没有开销 都是data分割的 <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/limiter.png"                                     ></font></p></li><li><p><font color=cornsilk><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/warp.png"                                     >warp 注意4 这个数字是由架构中每个SM的scheduler决定的 stall warp eligible warp 因此我们要最大化active warps</font></p></li><li><p><strong><font color=mediumseagreen>divergence 会执行所有分支 我们将分支按warp 划分</font></strong></p></li><li><p><strong><font color=pink>latency hiding <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/latency.png"                                     >类似于CPU的调度 latency就是时间 一般用clock cycle 计算大小</font></strong></p><ul><li><font color=cornsilk>P91 有趣的排队理论 就是需要同时并行的操作数&#x3D;延迟（cycle）*预期throughput throughput 与 bandwidth used interchangably bandwidth refer to as peak data transfer per time unit throughput refer to as any operations       rate metrics都是throughput单位 ops per cycle per SM 也可以进一步用warps表示也就是&#x2F;32 so the underlying thing of latency hidding is that you should increase the parallesiem to move like sequential ops without waiting </font></li></ul></li><li><p><font color=pink>latency hidding 总体而言需要更多的并行操作也就是需要更多的active warps 但是这个数量又是由memory and register 限制的所以configuration 很重要</font></p></li><li><p><font color=cornsilk>有趣的建议 <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/tipss.png"                                     ></font></p></li><li><p><font color=cornsilk>一些使用CUDA 的建议 <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/bsize.png"                                     >太大的block size 会使每个thread硬件资源很少 太小的 block size warp 数量太少</font></p></li></ul></li><li><h2 id="GPU-ARCH"><a href="#GPU-ARCH" class="headerlink" title="GPU ARCH"></a><font color=Pink>GPU ARCH</font></h2><ul><li><strong><font color=cyan>The GPU architecture is built around a scalable array of <em>Streaming Multiprocessors</em> (SM). GPU hardware parallelism is achieved through the replication of this architectural building block. </font></strong></li><li><strong><font color=cyan>P 68我们先可以把SM看作一个比较强的硬件 一个grid 对应一个 kernel 一个grid的block可以分配到多个 SMs 然后一个SM 可以有多个block 也可能来自不同的grid(kernel 并发)每一个线程都具有流水线</font></strong></li><li><strong><font color=cyan>SIMT warp为一个基本管理 thread warp中每一个线程的内存与寄存器与计算资源都是独立的 SM将 block划分为warps 所以最好为32的倍数</font></strong></li><li><strong><font color=cyan>Even though all threads in a warp start together at the same program address, it is possible for individual threads to have different behavior. SIMT enables you to write thread-level </font></strong></li><li><strong><font color=cyan><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/SM.png"                                     ></font></strong></li><li><strong><font color=red>一个block只能安排在一个SMs！！！记住知道执行结束都在一个SMs 同样的一个SM可以同时有多个block</font></strong><ul><li><strong><font color=cyan>一个grid其实就是整个device了只是支持kernel的并行操纵 然后有个SM商店 shared memory 按照block划分 register 几万个按照thread划分因此 一个block间的thread可以shared mem 交流 While all threads in a thread block run logically in parallel, not all threads can execute physically at the same time. As a result, different threads in a thread block may make progress at a different pace.同一个block中的thread以warp执行 所以实际没有物理并行 这里可能会在 shared mem访存时出现竞争 CUDA提供了block内部的同步函数 但是多个block 之间没有提供同步函数 </font></strong></li></ul></li><li><strong><font color=cyan>一个core通常有一个整数ALU和浮点ALU <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/device.png"                                     >gigathread 就是全局的安排block到SM的</font></strong></li><li><strong><font color=cyan>two warps and issue one instruction from each warp to a group of 16 CUDA cores, 16 load&#x2F;store units, or 4 special function units (illustrated in Figure 3-4). The Fermi architecture, compute capability 2.x, can simultaneously handle 48 warps per SM for a total of 1,536 threads resident in a single SM at a time. 我们的这个关键就是 分组 其实有四个组合 然后选择其中一个一个作为执行选项 然后对于两个warp scheduler 就是两条流水线 然后其实每一组调度都可以看作是并行的了 不用再去管物理上的运行了上面说的48 个warp就是 同时dispatch 48 个 而不是同时运行 48个</font></strong></li><li><strong><font color=cyan>64KB memory 被分成了shared memory 和L1 cache两者关系运行更改通过runtime API </font></strong></li><li><strong><font color=red>Fermi also supports concurrent kernel execution: <font color=bluseagreen>multiple kernels launched from the same applicationtion context executing on the same GPU at the same time.</font> Concurrent kernel execution allows programs that execute a number of small kernels to fully utilize the GPU, as illustrated in Figure 3-5. Fermi allows up to 16 kernels to be run on the device at the same time. Concurrent kernel execution makes the GPU appear more like a MIMD architecture from the programmer’s perspective.<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/conc.png"                                     ></font></strong></li><li><strong><font color=cyan>LD&#x2F;ST 使用来进行转换地址的单元 16 个也是因为并行的原因</font></strong></li><li><strong><font color=cyan>kepler dynamic parallelism 允许 nested kernel invoke ; Hyper-Q 避免一个失败的kernel 调用 idle CPU 太长时间 多个task queue</font></strong></li><li><strong><font color=cyan>P 79 nvprof profiling driven 性能测试初步 类似linux里的一个 profile Event and metric</font></strong></li><li><strong><font color=cyan>memory bandwidth; compute resource ; latency</font></strong></li><li><strong><font color=cyan>Warps are the basic unit of execution in an SM. When you launch a grid of thread blocks, the thread blocks in the grid are distributed among SMs.  就是可以多个相同grid block在一个SM，也可以一个SM有来自不同block 最终硬件上都是一维</font></strong></li><li><strong><font color=cyan>warp 的划分原则 consecutive threadIdx.x !! 最后是向上取取整warps 如果非整数倍会出现空闲的不活跃thread 但是仍然会消耗占用硬件自资源也就是最终都是一维的硬件实现</font></strong></li><li><strong><font color=cyan>Warp Divergence 就是分支判断的问题 会 连串掩码式地执行 在优化等级较高时时间开销接近正常 解决就是 让一个分支用warp size 与运行</font></strong></li><li><strong><font color=cyan><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/reso.png"                                     >仔细想想居然很大程度上我们的这两个是独立影响的</font></strong></li><li><strong><font color=cyan>P89 A thread block is called an <em>active block</em> when compute resources, such as registers and shared memory, have been allocated to it. The warps it contains are called <em>active warps</em>. Active warps can be further classifi ed into the following three types: 三种 selected warp stalled warp eligible warp selected 不多于4个 是不是类似于我所说的流水线 4个选项 </font></strong></li><li><strong><font color=cyan>block太小 可以认为与大block相比同样的共享内存能偶拥有的thread 数量较少 所有register等没有充分利用 ；太大，线程太多，没有足够的thread</font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li><li><strong><font color=cyan></font></strong></li></ul></li><li><h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a><font color=slatecyan>Synchronization</font></h2><ul><li><strong><font color=cornsilk>两个层面 host and device 2 thread </font></strong></li></ul></li><li><p><strong><font color=cornsilk><strong>device</strong> void __syncthreads(void) 一个让同一个block 的线程同步的函数</font></strong></p></li><li><ul><li><h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a><font color=yellow>Configuration</font></h2></li><li><p><strong><font color=cornsilk>配置函数 对于 blockdim 的innermost x 一般是32 的倍数 这个是有 warp 决定的 同时 一个block的thread数量不能超过 1024</font></strong></p></li><li><p><strong><font color=cornsilk>通常而言 block 数量越多 并行度越高 但是load throughput会下降 但是load efficency 更高 具有更高的achieved occupancy 但是实际上 由于 block 数量的限制反而会限制active warp </font></strong></p></li><li><p><strong><font color=cornsilk><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/bal.png"                                     ></font></strong></p></li><li><p><strong><font color=cornsilk>第一个常见的算法就是 reduction 树形结构</font></strong></p></li><li><p><strong><font color=cornsilk>有 neighbor reduction 和 interleave reduction 后者拥有更好的global memory的局部性所以性能更好</font></strong></p></li><li><p><strong><font color=cornsilk>unrolling loop 同样的一个方法循环展开真的非常快 wtf 注意这里是Unrolling loop 注意 同步函数是用来进行 一个block 之间的同步的 block之间无法同步 </font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li><li><p><strong><font color=cornsilk></font></strong></p></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CUDA-amp-Algorithm&quot;&gt;&lt;a href=&quot;#CUDA-amp-Algorithm&quot; class=&quot;headerlink&quot; title=&quot;CUDA&amp;amp;Algorithm&quot;&gt;&lt;/a&gt;&lt;strong&gt;&lt;font color=darkturquois</summary>
      
    
    
    
    
    <category term="CUDA" scheme="https://spikeihg.github.io/tags/CUDA/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://spikeihg.github.io/2023/10/20/CS224N/"/>
    <id>https://spikeihg.github.io/2023/10/20/CS224N/</id>
    <published>2023-10-20T06:09:31.000Z</published>
    <updated>2023-11-16T12:02:01.890Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CS224N"><a href="#CS224N" class="headerlink" title="CS224N"></a><font color=velvet>CS224N</font></h1><ul><li><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a><font color=MediumSpringGreen>前置知识</font></h2><ul><li><h3 id="TERM"><a href="#TERM" class="headerlink" title="TERM"></a><font color=yellow>TERM</font></h3><ul><li><font color=green>line up对齐</font></li></ul></li><li><p><font color=aqua>in-place 就是一般是method 直接俄改变变量的 eg 。.add()</font></p></li><li><p><font color=aqua>cross product in matrix 就是我们所学的叉乘</font></p></li></ul></li><li><h3 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a><font color=chocolate>什么是机器学习</font></h3><ul><li><p>机器学习我的理解就是在一定条件下完成一定任务，其中任务的完成由程序本身实现。</p></li><li><p>监督学习 类似回归问题和分类问题</p></li><li><p>无监督学习类似聚类算法，没有提前的正确规则，让机器找规律</p></li><li><p><strong><font color=azure>anaconda 的使用 </font></strong></p><ul><li>原理就是 conda安装更方便 类似aptitude 可以自动帮助安装 然后就是创建虚拟环境在每个虚拟环境下安装自己的包 避免版本和包冲突</li><li>conda create –name <env-name>  <package-name></li><li>conda env list</li><li>conda –help</li><li>conda activate <env></li><li>conda info -e</li><li>conda deactive 退出环境</li><li><font color=red>注意要关代理 创建环境的时候更新版本的时候也要关代理 可以设置使得能够在代理下使用但是有一点麻烦</font></li></ul></li><li><h3 id="pytorch-tutorial"><a href="#pytorch-tutorial" class="headerlink" title="pytorch tutorial"></a><a class="link"   href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html" >pytorch tutorial <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h3><ul><li><font color=pink>tensor 的维度 创建tensor torch.empty(3,4)里面是描述tensor 的shape attribute 两个数字说明是两个dim 然后3 说明有三个行向量 4就是每个行向量有4 个元素 empty 不会进行初始化的 1 dim 就是vector 2 dim is a matrix torch.zeros(),.ones(),.rand(), 要从已有的tensor 创建拥有一样shape 的 tensor 需要用法 *_like () method 具体就是这个中括号的层数 torch 也可以直接用python 的 list 和 tuple创建甚至是混合的；在创建tensor的时候可以确定dtype,然后也看可以使用方法.to(torch.int32)</font></li><li><font color=pink>数学操作 内置的算术操作针对每一个元素做标量操作 对于两个tensor 也是进行的in-place 操作 但是必须要相同的shape 否则runtime error 一个特殊的例外就是broadcast 详细思考一下 </font></li><li><font color=pink>braodcast 从shape的last to first开始比较，当相等 或者其中一个为1 或者其中一个不存在都满足 直到比较完 判断时候broadcastable 然后算数的规则是用prepend 1 不玩较小维度的维度 然后对应的每个维度取最大值 注意 in-place 操作也支持broadcast </font></li><li><font color=pink>理解broadcast 的关键就是意识到dim&#x3D;1 的时候我们可以把这个重复的地去乘</font></li><li><font color=pink>size 就是指一个维度的元素个数 从last 开始 dim 0 dim 1 注意是从0开始的，然后对应的是shape 的第一个(3,2,1) dim&#x3D;0 size&#x3D;3 注意是相反的！！！！！！</font></li><li><font color=pink>创建tensor 的时候指明一个required_grad 这样才能够在后面调用 grad时计算此项的gradient </font></li><li><font color=pink>仔细研读了一下 每一个tensor 都有维护一个.grad 来存储自己的偏导数 </font></li><li><font color=pink>torch.tensor()总是拷贝tensor 要尽量避免拷贝 detach() 改变 required属性</font></li><li><font color=pink>卷积的filter是一个多维的matrices 一定要注意的是我们的结果始终是一个2d matrix 对于一个filter不是多个filter 妈的 kernel 就是filter 带bias 的卷积操作就是卷积的时候加上bias 得到输出 传入kernel size 是一个int默认就是方正</font></li><li><font color=pink>dim 就是一个方向可以堆叠的方向 然后可以看括号来判断</font></li><li><font color=pink>N batch size 自己定义一些东西 dataset 可以抽象成一个 list  每一个元素就是一个 map 例如 path: label 之类的 feature 就是我们的prediction label 就是实际值 定义dataset 和 dataloader 就是第一步 注意一张定制化的思想 很不错面向对象编程</font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li></ul></li><li><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a><font color=orange>流程</font></h3><ul><li><p><font color=lightgreen>custom dataset and dataloader</font></p><p>   <font color=lightgreen>dataset 抽象定义为一个map 有一个annotation file 存储所有的样本的名字 还有存储的路径 两者结合可以得到一个图片的完整路径 然后预定义transformer 三个必要的 函数 ——init—— 就是 self.img_labels read csv 读入csv 然后定义dir和 transform  ——len——  ——getitem——  对于dataloader 设置加载方式 batch shuffle  多线程加速等</font></p></li><li><p><font color=lightgreen>layer</font></p><p>   <font color=lightgreen>Linear 就是一个layer 改变输入的最内层dim 的size 由输入的参数决定 注意我们的这个layer里面已经有预先设定好的bias 和 weight 相当于就是 对于图像可能就是一个 convolve </font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li><li><p><font color=lightgreen></font></p></li></ul></li><li><h3 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a><font color=pink>梯度下降算法</font></h3><ul><li>同步更新所有变量 </li><li>出发点是想要拟合一段数据 然后我们想让整个数据组的误差最小。因此我们求导。可以理解为山坡上寻找下降路线。由于公式会随着接近局部最小点而自己缩小前进距离这是一个学习。</li></ul></li><li><p><font color=seagreen>输入是一个特征向量 的函数求偏导本质就是我们在微积分里面学习的矢量函数求导链式法则 θ的每个分量看作一个维度 然后是复合函数求导</font></p></li></ul></li><li><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a><font color =violet>极大似然估计</font></h3><ul><li>就是我们依照描述的事件写出这个事件发生的概率表达式，这个表达式由一个变量（涉及概率密度）决定。我们想求这个变量使得改概率函数取一个最大值。</li></ul></li><li><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a><font color=Maroon>代价函数</font></h3><ul><li>感觉与目标函数类似，一般与误差函数具有相同或者相反的单调性，然后通过一些数学技巧进行改写，以简化计算。</li></ul></li><li><h3 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a><font color=Teal>Batch Gradient Descent</font></h3><ul><li>这个就是传统的梯度下降，每一次前进时都要求遍历整个数据集来更新计算代价函数然后求偏导，计算量是非常巨大与难以实现的。具体原因我们会发现，偏导数求得的公式与每一个样本都有联系，例如差平方求和之类的。</li></ul></li><li><h3 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a><font color=Aqua>Linear Algebra</font></h3><ul><li>在此再次向Pro.Strang致以最崇高的敬意。</li></ul></li><li><h3 id="注意点——向量拓展的梯度下降以及向量函数"><a href="#注意点——向量拓展的梯度下降以及向量函数" class="headerlink" title="注意点——向量拓展的梯度下降以及向量函数"></a><font color=gold>注意点——向量拓展的梯度下降以及向量函数</font></h3><ul><li><p>注意函数变量的两个层面，一个是输入样本的维度，即样本向量的每一个维度，另一个是拟合函数中的变量即θ。h(x)(假设函数)&#x3D;θ0<em>1+θ1</em>x1 + θ2*x2+…… .eg 最后写成矩阵点积 多元线性回归</p></li><li><p>通常向量n+1 个 第0个是1为了简化表达 其余都是一个特征维度</p></li><li><p>根据上述结论重写表达式就是将θ化成对应n+1维向量然后求偏导时乘以一个xj^(i)的值。</p></li><li><p>比列失调的等高线梯度下降可能出现震荡，使用特征缩放相当于变量代换更高效将值约束在-1，1之间大约 还有归一化处理 使得平均值在0 x1-u1 代换 本质就是线性组合 u1 就是平均值 x1-u1&#x2F;s u1 就是平均值 s就是标准差 就是概率论</p></li><li><p>关于学习率α 过大可能会波动或者发散 国小很慢 总之尝试不同的一系列值</p></li><li><p>多项式回归 但是我还是有问题 函数都是人提出来 没有机器自己去寻找</p></li><li><h3 id="Normal-Equation"><a href="#Normal-Equation" class="headerlink" title="Normal Equation"></a><font color=cyan>Normal Equation</font></h3><ul><li>线性代数永远的神，但是我已经忘记了~~~~~ 其实就是线代中的回归方程 男泵投影！！！！！</li><li>似乎用于线性回归，缺点：当n增大时会很慢 复杂度为3次方 而梯度下降可以正常的 大概10000为界限 例如 Word2vec 使用梯度下降法 而且只使用与线性 梯度是通法</li><li>pinv inv pinv 进阶求逆 可以是伪逆 可是当时没看</li></ul></li></ul></li><li><h2 id="Deep-learning"><a href="#Deep-learning" class="headerlink" title="Deep learning"></a><font color=tan>Deep learning</font></h2><ul><li><p><font color=red>简介。机器学习就是找函数function.在台大的课中只会有梯度下降 梯度下降开始的值朴素的是随机的，但是可能存在更好的 初始值全面的回归求解其实就是训练<br>模型就是我们提出的拟合方程 课程采用的是绝对值衡量</font></p></li><li><h2 id="piecewise-linear-curve所有线性的折线都可以用一组z来拟合-同理对于光滑的-我们可以无线细分-由piecewise-linear-curve-来逼近-进一步又由蓝色来逼近-！！！！！！！！！！！"><a href="#piecewise-linear-curve所有线性的折线都可以用一组z来拟合-同理对于光滑的-我们可以无线细分-由piecewise-linear-curve-来逼近-进一步又由蓝色来逼近-！！！！！！！！！！！" class="headerlink" title="piecewise linear curve所有线性的折线都可以用一组z来拟合 同理对于光滑的 我们可以无线细分 由piecewise linear curve 来逼近 进一步又由蓝色来逼近 ！！！！！！！！！！！"></a><font color=lavender>piecewise linear curve所有线性的折线都可以用一组z来拟合 同理对于光滑的 我们可以无线细分 由piecewise linear curve 来逼近 进一步又由蓝色来逼近 ！！！！！！！！！！！</font></h2></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/efunc.png"                                     ></p></li><li><p>y&#x3D;csigmoid(b+wx);  hard sigmoid w slopes b shift  </p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/bff.png"                                     ></p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/beauti.png"                                     ></p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ddd.png"                                     ></p></li><li><p>sigmoid 的个数自己决定</p></li><li><p>实际的y帽 叫做 label</p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/theta1.png"                                     ></p></li><li><p>batch 将N划分作batch随机的来求梯度</p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/epoch.png"                                     ></p></li><li><p>epoch 是所有包都看了一遍 update就是一次更新 不一样</p></li><li><p>batch size learning rate 都是hyper parameter</p></li><li><p>ReLU rectified linear unit cmax(0,b+wx)就是hard sigmoid</p></li><li><p>就可以在所有sigmoid 使用的地方用ReLU</p></li><li><p>统称为activation function 老师都用的ReLU </p></li><li><p>可以多层进行变换 layers 就是得到a后再带入进去</p></li><li><p>多次ReLU 意思就是</p></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/network.png"                                     ></p></li></ul></li><li><p>为什么更深 乐 老师太好玩了！！！！</p></li><li><p>overfitting 过拟合问题 worse on unknown data</p></li><li><p>backpropagation </p></li><li><h3 id="anoconda-创建指令是全局的conda-create-然后可以在里面下载包-用vscode-启动可以-注意激活的时候要把代理关了"><a href="#anoconda-创建指令是全局的conda-create-然后可以在里面下载包-用vscode-启动可以-注意激活的时候要把代理关了" class="headerlink" title="anoconda 创建指令是全局的conda create 然后可以在里面下载包 用vscode 启动可以 注意激活的时候要把代理关了"></a><font color=pink>anoconda 创建指令是全局的conda create 然后可以在里面下载包 用vscode 启动可以 注意激活的时候要把代理关了</font></h3></li><li><h2 id="jupyter-notebook-guide"><a href="#jupyter-notebook-guide" class="headerlink" title="jupyter notebook guide"></a><a class="link"   href="https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/install.html" >jupyter notebook guide <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h2></li><li><p>jupyter 可以使用命令行调用 </p></li><li><pre><code class="python">jupyter notebook 然后就进入了browser</code></pre></li><li><h2 id="Colab-使用"><a href="#Colab-使用" class="headerlink" title="Colab 使用"></a><strong><font color=slategray>Colab 使用</font></strong></h2><ul><li><p>python code 和 shell code 其中！接shell cmd cd除外 %cd</p></li><li><p>可以选择执行的硬件 GPU runtime type 里面</p></li><li><p>ctrl+ enter 执行一个代码cell</p></li><li><p>总体而言其实就是jupyter 只不过是个互联的jupyter.</p></li><li><p>左侧的文件图标查看结构 注意下载邮寄 可以上传到google硬盘</p></li><li><p>注意自己使用的时候是在google的GPU上 所以程序结束就会消失  注意自己保存</p></li><li><p><strong><font color=lightcyan>打开新的需要在file 里面upload notebook!!!! 可以的 注意一次只能有一个session 所以需要关掉前面的 notebook maybe<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/save.png"                                     >真的很不错一个tesla 真棒 然后我可以试试ssh之类的</font></strong></p></li><li><p><font color=yellow>然后现在发现了 ctrl+e 普通搜索很快 然后url 对url很快 因为对普通搜索会转换为我们的query 条目 然后会比较慢！！！</font></p></li><li><p><a class="link"   href="https://github.com/virginiakm1988/ML2022-Spring" >ML github repo <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></li><li><p>pytorch tensor 相当于 array 可以GPU 加速</p></li><li><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a><font color=green>Pytorch</font></h2><ul><li>tensor就是高维数组 </li><li>还得复习一下基本的python 语法 list dict class func 基本的一些使用 顺便复习写一写爬虫</li><li>tensor constructor numpy zero tensor unit tensor</li><li>每个batch 的 loss funct 可能存在不同的差别</li><li>sigmoid 或者 Relu 叫做 neuron 总体叫做 neural network</li></ul></li><li><h2 id="Python-review"><a href="#Python-review" class="headerlink" title="Python review"></a><font color=purple>Python review</font></h2><ul><li><p>if var in list:  if var not in list:</p></li><li><p>if var1,var2 not in list；</p></li><li><p>for key,value in dict:</p></li><li><p>for key in sorted(dict.keys()):</p></li><li><p>for value in sorted(dict.values())</p></li><li><p>answer &#x3D; input(‘please enter your answer’)</p></li><li><p>int(input(‘how old are you’)) </p></li><li><p>f”{var1_has_defined} {var2_has_dafined}” mesg_to_be_printed&#x3D;f””</p></li><li><p>python 函数调用时候 可以直接指定 def fun(var1,var2): …… fun(var1&#x3D;yes,var2&#x3D;no) 但是一定要记住名字 不要出错</p></li><li><p>默认形参也是放在后面</p></li><li><p>while some_list:</p><p> ​item&#x3D;list.pop()</p><p> ​do_with(item)</p></li><li><p>dict[‘new_key’]&#x3D;new_value</p></li><li><p>def fun(list_para):…     fun(list[:]) 传递一个切片  函数都是引用一定会修改变量的</p></li><li><p>可变形参 def func(*tuple_para): def func2(size,**dict_para):</p></li><li><h3 id="Class-in-Python"><a href="#Class-in-Python" class="headerlink" title="Class in Python"></a><font color=maroon>Class in Python</font></h3></li><li><p>class my_class(): 开头的书写方法</p><ul><li>def __init(self,para1,para2)__self 必须第一个</li><li>然后接着是 self.para&#x3D;para(实际传入实例类的形参)这样写之后this 相当于才拥有这些成员</li><li>​普通方法 def member_func(self): 不要忘记了self</li><li>如果要有具有默认初始值的属性 可以直接在__init()__ 下面进行写 self.prop&#x3D;1000 prop 不用出现在init括号里面</li><li><font color=aqua>继承</font></li><li>首先必须括号里写明继承的类 class derived(base):</li><li>super()._<em>init(para,para,para)</em>_注意里面没有self 继承全部内容</li><li>自己属性接着写就可以</li><li>可以重写父类方法 名字不同就可以</li><li>可以类实例作为成员 self.class_mem&#x3D;classA()</li></ul></li><li><p>这个 <strong>init</strong> 不是必须的方法 只是用来定制实例化时 类似的还有 _<em>self</em>_  _<em>next</em>_  等用来控制 迭代器的 同时呢 生成器 generator 是一个综合了上面方法功能的函数 yield  generator expression</p></li></ul></li><li><p><font color=green>文件操作</font></p><ul><li>with open(‘filename’) as name:  不需要close了 因为with</li><li></li></ul></li></ul></li><li><h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a><strong><font color=cornsilk>工具</font></strong></h2><pre><code>    *  training data 上的loss过大</code></pre><ul><li>Model bias 就是 我们的函数太简单 解决方法 一 增加 特征量 二 增加layer deep learning</li><li>优化问题 梯度下降的问题</li><li><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/optm.png"                                     ></li><li>怎么解决 优化的问题 next lecgt</li><li>一定区分 overfitting 和 优化问题 一个是test data 一个是 training data<ul><li>overfitting <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/freestyle.png"                                     ></li><li>解决方法 增加 training data 二 data augmentation 就是自己创造一些条件 创造一些资料 需要有道理</li><li>减小弹性 增加限制</li><li>full- connected比较有弹性目前我们讨论的； CNN 比较无弹性<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/stop.png"                                     ></li></ul></li><li>区分 overfitting 与 model bias  存在一个complexity 与 bias 关系</li><li><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/trade.png"                                     ></li><li>刚刚好的<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/aaa1.png"                                     ></li><li></li></ul></li><li><h3 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a><font color=pink>Tips</font></h3><ul><li><font color=mediumspringgreen>critical point saddle point &amp; local minima 前者更多 通过hessian 矩阵来判断 特征值来判断 全正或者全负local其余就是saddle point</font></li><li><font color=mediumspringgreen>针对local point 的方法 batch size  一般来说越小noise 越多但实际上更好 但是在并行计算下可能更慢 第二 momentum 惯性一样的下一步加成</font></li><li><font color=mediumspringgreen>learning rate 的问题 有一个方法 叫做 Adam Optimizer 就是RSM 加上 momentum 的结合 可以动态改变learning rate 。 也就是说我们的learning rate可能也是 loss stuck的原因，而非 critical point </font></li><li><font color=mediumspringgreen>loss 函数也有影响 对于分类问题而言 使用最多的 是 cross entrophy 原来是用似然函数 好处就是 可以将整个surface 放得平缓</font></li><li><font color=mediumspringgreen><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/Fea.png"                                     >理解权重影响的问题 和这个surface是怎么来的 我们要不断修正的是w1 w2  mean 就是平均值 standard deviation 就是标准差 标准化  数学的影响就是 loss converge 收敛更快 但是还是有个问题，在实际的多层神经网络中 每经过一层 可能分别差别又会变大 所以我们还是需要不断地进行normalization 可以是activationfunc 之前 也可以之后 sigmoid 最好之前 因为可以化到-1 1 之间使得函数的值变化比较大<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/norm.png"                                     > 这个优化提升的是训练速度 主要是<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/arx.png"                                     ></font></li><li><font color=mediumspringgreen>CNN 卷积神经网影像处理，一个图像就是一个RGB的三位channel 的tensor 就是一个高维的叠加的数组 拉直就是一个向量 但是我们一般不会全部进行训练 我们会进行一定的相关的简化receptive field 这样做的一个理论 就是探查pattern 用pattern 去进行识别</font></li><li><font color=mediumspringgreen>一般通常选取都是三个channel 然后此时的长宽称为kernel size 3X3 通常就可以了 stride hyper para 超出的部分进行padding <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/stri.png"                                     ><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/filter.png"                                     ></font></li><li><font color=mediumspringgreen>fully connected layer弹性最大  receptive field 共享参数 减小了弹性这两个加起来就是convolution al layer 对应的就叫 CNN model bias 较大<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/fmap.png"                                     >这里的channel变成了neuron 的个数了</font></li><li><font color=mediumspringgreen>pooling 方法 max pooling  的方法 为了减少运算量 现在开始减少了<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/CNN.png"                                     >下面那个是flatter 还有一个重要应用 就是 playing go</font></li><li><font color=mediumspringgreen>分类问题softmax的原因简单解释 就是 我们用one-hot 向量表示我们的类 然后用1 然后我们将softmax 将其转换为-1 到 1 当然我觉得可能还是因为概率分布的问题就是越大的比例越大</font></li></ul></li><li><h2 id="self-attention-自注意"><a href="#self-attention-自注意" class="headerlink" title="self-attention 自注意"></a>self-attention 自注意</h2><ul><li><font color=pink>问题引入 加入我们处理的input data是一个向量序列 而不是一个向量。 对应的输入也有不同的种类。比如说输入的每一个向量都计算一个label 例如判断文本每个单词的 词性 或者类似的分裂问题 。或者一个输出 比如对一句话进行定义  反正应用情形自己去想象 最复杂也许是seq2seq 输出的已是一个序列 例如翻译</font></li><li><font color=pink>sequence labeling 如果仅仅使用前面的network 然后单独输入的话存在一个巨大的问题就是无法做到考虑上下文使用情形有限</font></li><li><font color=pink>attention is all you need <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/matr.png"                                     ><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/attention.png"                                     ><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/multi.png"                                     ></font></li></ul></li><li><h2 id="Seq2seq"><a href="#Seq2seq" class="headerlink" title="Seq2seq"></a>Seq2seq</h2><ul><li><font color=pink>encoder FFN feed forward network </font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CS224N&quot;&gt;&lt;a href=&quot;#CS224N&quot; class=&quot;headerlink&quot; title=&quot;CS224N&quot;&gt;&lt;/a&gt;&lt;font color=velvet&gt;CS224N&lt;/font&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;h2 id=&quot;前置知识&quot;&gt;&lt;a href=</summary>
      
    
    
    
    
    <category term="NLP" scheme="https://spikeihg.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Begin_Again</title>
    <link href="https://spikeihg.github.io/2023/10/15/Begin-Again/"/>
    <id>https://spikeihg.github.io/2023/10/15/Begin-Again/</id>
    <published>2023-10-15T03:21:50.000Z</published>
    <updated>2023-11-17T13:14:21.612Z</updated>
    
    <content type="html"><![CDATA[<h3 id="计算机科学中的自然原理"><a href="#计算机科学中的自然原理" class="headerlink" title="计算机科学中的自然原理"></a>计算机科学中的自然原理</h3><ul><li><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong><font color =green>感谢过去一年中给予我启发的诸多事物，无论是一本书如CSAPP，一堂课如数字电路，或者一个人如Prof.Strang，所有这些人事都是促使我更加严肃地审视计算机科学与其背后丰富而美丽的思想。所以，我希望继承那些前辈，那群充满热情与想象力的先驱的工作，在这里对CSAPP中的美妙理论进行简答而又深刻的阐释（有点自大哈哈哈哈），希望在有限的时间与文字中，探寻科学与自然的美。</font></strong></p></li><li><h2 id="你好！世界"><a href="#你好！世界" class="headerlink" title="你好！世界"></a><font color=pink>你好！世界</font></h2><blockquote><p>萨冈和她的你好忧愁，我和我的你好世界。Hello World,梦开始的地方，我们就从一个hello world.c 程序的生命开始进行一场快速的计算机世界漫游。</p></blockquote><ul><li><font color=aqua>程序是怎么编写的呢，首先我们会需要一个文本编辑器，也就是我们常用的devc++或者是vscode，vim，emacs。文本编辑器就是编辑文本文件的，我们缩写的源文件也属于文本文件。文本文件就是只含有阿斯克码的文件，其余的文件都是二进制文件。编写后，我们就可以通过一系列指令来使程序运行。对于一个.c文件而言。我们可以用gcc 命令来生成可执行文件。gcc就似乎编译驱动程序 这是nux终端的命令。当启用后，首先运行的是预处理器，对于含#的指令，如#include预处理器会将头文件全部插入到源文件中，同时完成宏的拓展。这是纯粹的文本替换，其他什么都没有发生。然后就是编译器，编译器将.c文件转换为汇编语言格式，可以理解为机械码的助记符，这是程序员可以阅读和编写的。然用汇编器汇编为二进制，此时是一个可重定位的可执行文件，此时通过ld将引用的库一起链接形成一个可执行文件保存在内存中。调用时，通过加载器加载到cpu进行执行。</font></li><li><font color=pink>几个关键概念。首先，计算机的硬件组成。CPU，内存空间极其缓存结构和虚拟地址，网络与I&#x2F;O 进程与线程。这里我们能慢慢接触到抽象与设计的感觉。</font></li><li><font color=blue><em><strong>一切皆文件 ，linux将设备文件都以同一种方式进行处理，让建立一种广泛而统一的接口成为可能</strong></em></font></li></ul></li><li><h2 id="从理论到实践"><a href="#从理论到实践" class="headerlink" title="从理论到实践"></a><font color=MediumAquamarine>从理论到实践</font></h2><p><strong><font color=ForestGreen>在学习每一个章节的过程中，我们会逐渐感觉到与一些相似的内容串联了起来。这种知识路径形成环，环闭合的感觉非常类似于我在高中看科幻小说时形成的想法。哈哈哈哈哈。这里就列举所有对应的知识群，然后随着不断学习深入，持续补充~~（突然想到也许我得去补充几个emoji和颜文字）</font></strong></p><ul><li><strong><font color=Lavender>二进制族群——数字电路的设计非常优美简洁;CPU流水线；</font></strong></li><li><strong><font color=lavender>程序机器级表示——优化技巧</font></strong></li><li><strong><font color=lavender>链接——Makefile脚本和Cmake 的使用 以及Vscode 相关json文件的配置</font></strong></li><li><strong><font color=lavender></font></strong></li><li><strong><font color=lavender></font></strong></li><li><strong><font color=lavender></font></strong></li><li><strong><font color=lavender></font></strong></li><li><strong><font color=lavender></font></strong></li></ul></li><li><h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a><font color=orange>FAQ</font></h2><ul><li><font color=pink>buffer overflow 字符串溢出覆盖栈上内容读取字符串造成</font></li><li><font color=pink>为什么重载函数不能返回区别，因为编译器重整符号时只会考虑函数名字和参数类型</font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li><li><font color=pink></font></li></ul></li><li><h2 id="数据表示"><a href="#数据表示" class="headerlink" title="数据表示"></a>数据表示</h2><ul><li><font color=brown>浮点数与整数两种格式，拥有不同的表示方法，所以进行类型转换时要注意。整型通过补码表示。公式是唯一的-2^n + 源码的二进制。浮点数是一中近似的表示，对于太多小数位，进行加减时可能出现差。还有就是有符号与无符号的区别以及对应的溢出问题，截断问题。最后就是其实很多函数%d 并不关心真正的类型也不会检查，这只是告诉函数将以一个整型的方式进行内存寻找。</font></li><li><font color=cyan>big-end &amp;&amp; small -end 大小端 注意只存在于多个字节的数据的问题 例如0x12345678 小端机就是 78 56 34 12 就是地位在小地址，注意在网络编程获取主机名于端口时可能有影响，需要调用相应修改转换函数。</font></li><li><font color =Orchid>计算机处理加法乘法都远远快于除法。同时可以尽量写位运算，当然编译器可能也帮你优化。数字的表示与实现都很精妙 前辈的只会佩服。</font></li></ul></li><li><h2 id="汇编简介"><a href="#汇编简介" class="headerlink" title="汇编简介"></a><font color=PowderBlue>汇编简介</font></h2><ul><li><font color=Orchid>首先我们要知道，计算机只认识01，01 构成了整个世界，在数字电路的学习中我们也能有这样的体会。事实上，我们所写的程序最终会转换成01的机器代码，所有的文件不论是文本视频图片文件最终都是01串。而汇编代码就是位于机器代码的一种助记符</font></li><li><font color=sandybrown>gcc -Og O1 O2 O3 通常而言 O1 分析 O2 可接受优化 Word因特尔的字就是 16bit 寄存器 6个参数寄存器 rdi rsi rdx rcx r8 r9 然后返回 rax 栈 rsp 计数器PC rip 然后就是被调用者寄存器 我们来看一下机械逻辑是怎么形成过程的。栈，核心，栈帧栈的空间。然后就是三个部分，传递控制，传递数据，分配和释放内存。控制传递依赖两个命令与rip call 会将放回地址即下一条弹入到栈中，然后rip变为label的地址。ret就会压栈然后rip回到返回地址。 数据控制就是通过栈存储多余参数调用，被调用者保存寄存器数据，局部变量存储完成的。</font></li><li><font color=lightcoral>指针与数组，数组就是转化为i指针运算。通过改变内存寻址来实现c语言中的指针类型。结构而言，字段就是基地址偏移量。引入重要的对齐概念：一句话任何大小为K字节的数据类型的首地址都要为K的倍数，intel不强行对齐。因此就可能会补全。buffer overflow 就是字符串溢出覆盖栈上数据，然后对应防范有栈随机化和金丝雀技术。 alloca 栈上分配空间。</font></li><li><font color=wheat>浮点数，单独一组寄存器 ymm 256 64bytes,xmm 32bytes. SSE,AVX架构。包含头文件可以使用。</font></li></ul></li><li><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a><font color=yellowgreen>优化</font></h2><ul><li><font color=greenyellow>优化面对的挑战。memory aliasing 就是同一个地址由多个指针变量使用，一些激进优化可能导致问题。函数调用对全局状态的改变。</font></li><li><font color=lightblue>CPE，周期每元素一个度量单位。延迟，就是严格顺序执行时一个操作需要的实践。发射时间就是两个相同命令执行所需的间隔，为1就是完全流水化时间。吞吐量，就是发射时间的倒数乘以功能单位。优化方向有减少循环内部计算。减少函数调用，合理内联。减少同一值的反复求值过程。循环展开。多路合并，也就是累计变量。写出简短便于求值使用数据传递控制的条件判断。然后就是使用向量操作。减少内存引用，使用局部变量存储。然后就是重新结合提高指令级并行度。 </font></li><li><font color=plum>关键路径，就是分析优化的一种指令级维度的技术。将汇编代码进行分析，观察其中的循环寄存器以及相关数据链，然后数据链对应就是一个关键路径，看关键路径有无线性缩短。乱序处理，流水线，分支预测，投机执行。CPU的技术。程序分析。unix 上的gprof ，linux上的valgrind, intel的vtune，以及nvidia的nsight 好多profiler。其中gprof 使用需要加一个-gp 选项在gcc中</font></li><li><font color=cadetblue>Amdahl’s law 就是想要加速一个系统，其加速比取决于加速部分时间占据整个系统的比重以及加速程度。</font></li></ul></li><li><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a><font color=cornflowerblue>内存</font></h2><ul><li><font color=coral>DRAM，SRAM，ROM，memory ,cache .等名词分清楚。SRAM 构成高速缓存的物理媒介快贵。DRAM构成主存的媒介也就是运存。ROM一般指磁盘一类的flash disk ,CD , ssd 都是不同的存储。</font></li><li><font color=rosybrown>DRAM 芯片结构。单个芯片有超单元矩阵构成，每个超单元一般有一个byte.然后2位地址引脚，8位数据引脚掌控数据的传输和行列索引。将芯片封装乘模块。叠8个，一次64位。通过内存控制器广播来讲相同索引的8byte数据聚合成一团数据。改进 DDR SDRAM 双倍数据速率同步DRAM 就是两倍的时钟上升沿</font></li><li><font color=olive>ROM是一类统称（非易失性存储），目前最主流的是flash memory。然后还有最新的SSD。ROM 上存储的一些程序叫做固体firmware 例如bios.通过总线进行访存。不过典型计算机使用的是磁盘技术。 连接设备i&#x2F;o 桥 ，系统总线与内存总线。io设备诸如键鼠GPU都是通过io总线尤其是PCI(外围设备互联总线)连接的，io总线比系统和内存总线慢，但是功能更加多样。</font></li><li><font color=springgreen>DMA磁盘。 磁盘直接内存访问，将磁盘内容发送到主存后再发送一个intercurpt型号。SSD使用闪存技术趋势，存储器尤其是DRAM 渐渐跟不上CPU的发展，差距越来愈大。随着单核性能趋近饱和，多核处理器出现，吞吐量成为另一个限制条件，而不再是延迟。</font></li><li><font color=aqua>locality 。深刻而间接的原理——局部性。时间局部就是重复变量，空间就是步长越小的引用</font></li><li><font color=aqua>memory hierarchy缓存实现的基本原理。通常将k+1层的数据c化为连续hunk成为block，与k层的cache交换都是以block作为一个传输单元。然后缓存命中就是k层中找到要访问数据，反之就是不命中。不命中有很多原因种类。冷不命中就是缓存开始时空的。然后由于很难做到随机任意替换的策略，也许是某种倍数一一映射替换策略可能导致冲突不命中。然后如果我们访问的工作集超过缓存的大小会发生容量不命中。寄存器文件由编译器管理，l1 l2 L3 缓存由硬件直接管理可以做到任意替换策略。主存由os 即虚拟内存。磁盘可能由分布式内存软件管理。 TLB 翻译后备缓存器由 硬件MMU管理。</font></li><li><font color=cornsilk>存储器结构实现 地址查询的实现本质是一种简单的哈希查询。S 组数，整个地址空间划分成组，每组有许多行，每行有一个有效位，标记为以及块，块中有好几位。 BxSxE ,依据每个组中的行数分三类，E&#x3D;1 直接映射高速缓存 组选择，行匹配，字抽取</font></li><li><font color=burlywood>理解划分，t,s,e 首先 s 划分组划分的是cache的组数 会比+1层的组数少，所以也许存在倍数映射，这是靠t标记位实现的，所以t+s真的唯一确定k+1内存块的位置。所以判断的 时候不仅要看有效位还要看t标识位。所以有时候会存在内存抖动问题就是冲突不命中刚好同一行反复驱逐</font></li><li><font color=cyan>组相联高速缓存 ，区别就是需要扫描标记位和有效位，因为同一组的所有行都有可能拥有有效数据，同样的在驱逐行时，也需要一定驱逐的策略。最近最少使用.eg</font></li><li><font color=pink>全相连高速缓存 只有一个组，所以关键是在扫描标记位和有效位 需要并行搜索标记，所以一般用于小的 eg TLB</font></li><li><font color=lightgreen>写操作，两个类型。在写命中时，就是cache中有需要被写的对象时，直写就是直接改变内存和cache，写回就是改变cache,维护一个改变位，推迟改变内存。 在写不命中时也有两个，写分配就是写内存的同时把其加载到cache,非写分配就是不加载。通常我们考虑写回加写分配。 i-cache缓存指令只读,d-cache 缓存数据。总结上面的影响，cache大小。越大命中率越高，但访问时间越长。块大小，越大，空间局部性越好，时间局部性越差，因为行数越少越容易被替换，相连度，越大越复杂，命中使&#x3D;时间越长，但是不命中处罚越低，</font></li><li><font color=goldenrod>应用 矩阵乘法优化。。</font></li></ul></li><li><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a><font color=Tan>链接</font></h2><ul><li><font color=green>编译驱动程序gcc 一套流水作业-v查看注意最后执行的时候会调用一个系统的加载器来复制到内存并转移控制ld 静态链接器在详细认识ld前要一下基本认识。ld两大基本任务。符号解析和重定位。symbol resolution and relocation .符号解析式将符号引用与符号定义关联。重定位是将符号定义与内存关联。大部分指令都有汇编器编译器确定好，ld仅仅奉命完成</font></li><li><font color=yellow>可执行文件，三种可重定位，可执行，共享（特殊的可重定位），linux是ELF，windows是PE，可重定位目标文件的格式。ELF头然后中间很多节(.session)然后是节头部表。.text 代码 .rodata .data .bss .symtab .rel.text .rel.data几个比较重要的 .bss 未初始化的全局静态 以及初始化为0的 节省空间函数就在.text里面显然</font></li><li><font color=deepskyblue>符号表 符号：三种：模块m定义的全局符号（函数与全局变量），模块m引用的全局符号，m定义的局部符号（static函数和只被m引用的全局以及静态变量）注意所有局部变量都没有条目（栈）因此可以使用static 隐藏模块的函数(模块就是一个可执行二进制文件)。symtab 包含一个条目的结构数组对应可看书P469 readelf 程序可以看二进制文件</font></li><li><font color=pink>符号解析，对于局部变量编译器确保唯一。编译器处理全局符号。对于全局符号，划分强弱，以处理重命名情况。 一，不允许有多个同名强符号。二，一个强多个弱同名，选择强，三，多个弱同名任意选择。函数与初始化了的全局变量为强，未初始化的全局变量为弱。 -fno-common 来使得不能生成common二唯一变量。我们使用了静态库技术。模块打包成库文件。对于实际链接时，加载器只会复制库文件中实际引用的部分，减少内存浪费。静态库的格式是archive.  .a 后缀 AR工具自己创建 。 –static 参数告诉驱动程序gcc生成一个完全链接的可执行文件，也就是说可以直接执行了，不需要动态链接。</font></li><li><font color=cornsilk>重定位 两步，将所有输入模块的节聚合然后分配到具体的运行时内存，唯一绝对的地址。（定义）。将引用是其指向正确的地址。重定位符号引用：PC相对引用和绝对引用两种。可执行文件，格式多了.init 入口点 组织成片，对齐。加载execve函数可以调用加载器。 运行时内存映像。0x400000开始本质是fork了一个子进程</font></li><li><font color=lightgreen>动态链接，动态链接器.so  DLL -shared 参数指示创建一个共享文件，-fpic 创建位置无关代码。共享库就是不复制模板引用的节，而是一些用于定位到 信息，等到实际执行的时候，再利用信息重定位。运行时动态链接dlopen接口打开，dlsym引用一个符号 dlclose 关闭 java也是类似使用c接口的</font></li></ul></li><li><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a><font color=Maroon>进程</font></h2><ul><li><p><font color=yellowgreen>进程就是一个运行的程序的实例。可以从功能上理解就是一个具体完成我们程序的过程。从组成上就是包括一系列的物理资源。包括内存，寄存器文件，控制器，内核栈等信息。总之就是上下文。</font></p></li><li><p><font color=salmon>异常，，就是逻辑控制流发生改变的情况，event事件也是如此。 异常发生在内核模式下。异常有中断interrupt 陷阱 trap 故障 终止。 终端就是硬件上，异步发生的。 trap 就是系统调用 system call  对于异常有三种情况 Icur 返回 Icur Inext 或者直接俄abort。 </font></p></li><li><p><font color=yellow>shell 执行一个命令就是fork 了一个新的进程并发 就是多任务 多进程 很多错误都是有定义的 有硬件设计者或者是内核维护 同样的异常处理程序也是。 可以通过 errno来查看 函数就是 stderror(error)</font></p></li><li><p><font color=deepskyblue>进程</font></p><div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="keyword">include</span><span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">pid_t</span> <span class="title">getpid</span><span class="params">(<span class="type">void</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">pid_t</span> <span class="title">getppid</span><span class="params">(<span class="type">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">pid_t</span> <span class="title">fork</span><span class="params">(<span class="type">void</span>)</span></span>;<span class="comment">// 子进程得到的是副本</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">execve</span><span class="params">(...)</span></span>;</span><br><span class="line">  <span class="function">unsighed <span class="type">int</span> <span class="title">sleep</span><span class="params">(ui)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">pause</span><span class="params">(<span class="type">void</span>)</span></span>;</span><br><span class="line">  <span class="comment">// 还有可以设置环境变量的sysm call env</span></span><br></pre></td></tr></table></figure></div><p><font color=deepskyblue>进程三个状态 运行 停止 终止 停止就是挂起 可以接受信号后继续运行 其中终止三种 接受到一个信号，主程序返回，exit函数</font></p><p><font color=pink>理解子进程共享状态 关键： 副本虚拟内存的副本。仔细研究就是 相同的执行程序，内存，data等节。然后相同的用户栈信息，共享文件描述符，共享共享库也就是相同的工具 最大不同就是PID 子进程是0 父进程是子进程的PID返回对于fork 一次调用两次返回 注意这是系统调用 从内核返回到用户模式 并发执行父子进程 </font></p><p><font color=lightgreen>进程操作，主要是理解不用背。 未回收的进程就是僵尸进程交给init 进程 PID&#x3D;1 所有进程的祖先 waitpid wait 可以等待并且有一定的行为可以操作   fork 和 exevce 就是实现 sh的关键 大概就是 fork 一个子进程然后进行 execve 执行 对应的命令</font></p></li><li><p><font color=lightblue>信号 linux 信号 可能来自内核检测到一个系统事件(event) 也可能来自其他程序的kill发送 接受三种 忽略 终止 或者信号处理程序</font></p></li><li><p><font color=cornsilk>strace 命令 可以使用-static 编译后查看程序中所有系统调用的轨迹 pmap 显示进程的内存映射 &#x2F;proc 内核提供的一个可以在用户模式下查看系统信息的文件 还有&#x2F;sys   execve 在内存里拥有一个内存栈 存储有argv 和 env 以及初始化函数的栈帧 非常的good</font></p></li><li><p><font color=pink>信号</font></p><p><font color=pink>信号是操作系统提供的内核。接受信号的物理实现 内核为每一个进程维护两个位向量,pending &amp; blocked.规则：一个类型至多一个待处理信号，多余发送直接丢弃。进程可以 选择性阻塞信号，这样的信号不会被接收，但是能够发送，只要传送信号，pending就会置为，只要接受，pending就会清除，这里接受可以理解为成功捕获并响应。更准确的说是trap 陷入那一刻起就恢复，因此可以执行handler K 时 捕获k<br>进程组 一般子进程会具有父进程的组pid。 job 一个前台job 很多个后台job job 就是一个进程组<br>signal 函数可以修改信号默认行为 每个信号都有默认行为 sigkill sigstop 不可修改 <br>编写信号处理程序的忠告 处理程序简单 调用异步安全函数sprintf 之类不安全。 保存errno 对全局变量访问期间要暂时阻塞信号 volatile声明防止缓存不一致 sig_atomic_t 声明变量 单变量原子操作</font></p><p>Richard Stevens<br><font color=pink>我们每次一个命令执行完后都会return main 所以当前进程会终止 然后被也许 init 或者父进程回收 子进程也会继承信号阻塞的信息向量 信号许多时候会造成竞争，所以我们也需要禁止某种操作，所以我们需要阻塞某些信号。 最后一个 sigsuspend 函数用于等待操作 详细请见 我们的P527 讨论<br>非本地跳转setjump longjump 函数实现的 可以超过一般的处理程序调用的规则进行调用</font></p></li></ul></li><li><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a><font color=lightgreen>虚拟内存</font></h2><ul><li><font color=lightgreen>虚拟内存针对核心对象的是主存</font></li><li><font color=lightgreen>虚拟内存的核心思想就是把磁盘的所有字节划分为一个连续的数组构成一个虚拟地址空间。然后将主存划分为一个物理地址空间，将磁盘的内容缓存在主存上，类似于SRAM缓存体系，这个就是DRAM 缓存体系，很多地方是相同的。我们有操作系统维护一个于虚拟页数（就是缓存里面的块）相同的一个PT（page table 页表） PTE一个条目里可以简化为一个有效位标志是否被缓存，以及一个物理地址字段对应其被缓存在主存上的实际地址。一个page 有三个状态(未分配就相当于磁盘未被使用；分配未缓存，已经被分配例如使用了malloc,但是还没有被加载到主存中；已分配已缓存，此时有效位置位)。现在你直到了malloc 的实际用法。还有就是因为巨大的不命中处罚，所以一个虚拟页较大，并且全相联。同时按需调度，到最后一刻才真正加载到主存。 getrusage 函数可以查看缺页情况。</font></li></ul><p><font color=lightgreen>虚拟内存如何实现一个统一的内存图景。这样想，我们任何一个程序的开始都一样，这个是虚拟地址，因为内核为每一个进程都维护了一个完整相同的独立的虚拟地址页表，并且虚拟地址要翻译为物理地址，所以啦，我们只需要在虚拟地址向物理地址的映射做一点手脚，我们认为控制这个映射就可以实现任意内存分配 简化加载，我们可以划出虚拟页表指向目标文件中的内容，这就是文件内存的映射，mmap 可以在应用层控制。 简化内存分配 malloc 实际的物理地址可以散落各处 实现内存保护。有几位标识读，写，执行权限。CPU 每次产生一个地址都需要查看PTE 所以在翻译的硬件MMU 中有一个缓存 TLB了解就好 翻译过程可以感兴趣再看看。还有就是使用了一个叫做多级页表的方式减少内存占用。</font></p><p><font color=pink>图景的实现原理。内核为每一个进程都维护了一个虚拟地址空间。并将虚拟内存组织成区域也叫做段。例如数据段，代码段，共享库段。实际过程中内核为每一个进程记录一个task_struct 的结构数组，里面包含着进程上下文信息。其中mm_struct 记录了有关虚拟地址的信息。在这个结构中存在一个链表每个node 对应一个段的相关信息。 缺页处理，首先判断是否位于虚拟内存内，如果不在就触发一个段错误。1 .然后判断权限是否对应，如果错误 2.然后开始替换，然后返回到除法信号的指令再次翻译地址。注意虚拟内存上的分配与磁盘上的存储是两个不同概念。只有当前执行的时候我们才加载，而加载的实际含义语义其实是让它具有虚拟地址。让其映射到虚拟地址空间！！！！！！！！！好好理解。抽象成一个空间集合！！！！简洁而有效。</font></p><p><font color=deepskyblue>memory mapping。 定义由上面其实页明白就是将一个虚拟内存区域与一个磁盘的对象关联起来，然后初始化这段虚拟内存的内容。映射磁盘对象的时候，有两种。对于Linux普通文件，将文件区分成片，映射到对应的虚拟内存页面。实际上并没有进入物理内存，而是使用按需调度机制。还有就是匿名文件，其实就是选择物理内存上一个牺牲页然后覆盖为0，实际上也没有磁盘的流量。 现在我们特殊讨论一下我们的共享对象。也就是映射的实际情况。首先，对于我们的这个共享对象，我们只需要一个物理内存中的副本，每一个进程可以在自己各自的不同的虚拟内存段上映射，同时每一个进程对于该共享对象的修改都是公开的。 同时还有私有对象，即每一个都是独立的。这种独立的实际事项方式是，先共享映射不过我们设置只读，当正在有探测到写入的时候，我们在复制该对象给写入的进程，尽量推迟从而提高效率。这就是写时复制技术。这也是fork 保持独立的实现原理。私有的，写时复制。execve函数就是一个删除现存虚拟内存重新映射的一个过程 然后mmap 函数可以让我们要求内核开辟虚拟内空间然后把我想要映射的对象关联起来。至于malloc 显式分配器的实践就是一个应用，可以参看书P587 .</font></p></li><li><h2 id="系统级I-x2F-O"><a href="#系统级I-x2F-O" class="headerlink" title="系统级I&#x2F;O"></a><font color=salmon>系统级I&#x2F;O</font></h2><ul><li><p><font color=salmon>一切皆文件的终极体现。就是将所有的i&#x2F;o设备抽象成文件，提供统一的文件接口。 打开文件得到一个唯一的文件描述符。0 stdin 1 stdout 2 stderr. k seek记录文件位置。读文件，读过大小限制后会自己触发一个EOF 而非有这个东西。文件。普通文件，套接字文件，目录。还有一些其他的。每个进程都会记录当前的工作目录，可以通过 cd 命令改变</font></p></li><li><pre><code class="cpp">#include&lt;sys/types.h&gt;#include&lt;sys/stats.h&gt;#include&lt;fcntl.h&gt;int open();int close();int read();int write();// Richard Stevens 和他的RIO包 R.I.P 缓存的使用减少系统trap// 针对不同的应用情景选择不同的i/o 自己写包装更好的尤其是网络编程//</code></pre></li><li><p><font color=salmon>共享文件的实现，维护三个表，针对进程也有一些东西。同时fork的时候也是这样的。</font></p></li></ul></li><li><h2 id="并行编程"><a href="#并行编程" class="headerlink" title="并行编程"></a><font color=yellow>并行编程</font></h2></li><li><p><font color=cyan>线程，信号量是实现对全局变量的访问。防止竞争。竞争可以使用进程图来直观表示。同时要防止死锁。还有很多，好几个基于线程进程，i&#x2F;o复用的编程模型</font></p></li><li><p><font color=blue>Open MPI 和 mpch 似是两个不同的mpi 实现 我看的教程似乎是 mpich ,但是一般而言都可以如果只是学习的话 我不过上次我似乎安装的是 openmpi</font></p></li><li><h3 id="MPI"><a href="#MPI" class="headerlink" title="MPI"></a><strong><font color=Teal>MPI</font></strong></h3><p><strong><font color=DarkCyan>这里就把mpi的使用在这里写了。先补充一点前置知识。冯诺依曼体系。cpu主存分离。导致大多时钟时间去访存。进程就是一个程序的实例可以看成一个综合体包括I&#x2F;o设备即一组文件描述符表，然后主存，前两者共同由虚拟地址实现。此为被处理器表现为独享。多任务即并发。每一个执行时间片。上下文切换。因此硬件计算的优化集中在对冯诺依曼体系的优化大致有如下几个。<br>Cache 在主存与寄存器之间设置三层高速缓存，SRAM，利用局部性原理<br>虚拟地址，可以看作讲主存作为磁盘文件的Cache.同时还有很多好处，如简化加载链接，提供更安全的地址守护等。<br>指令级并行<br>线程级并行TLP 细粒度多线程就是一个线程每执行他的一条指令就切换。粗粒度就是在遇到需要较长时间的指令才切换<br>SMT 同步多线程<br>SISD 单指令流 单数据流 SIMD 单数据多指令流 处理向量运算 大型简单计算GPU就是 处理图像 大量线程 具体可以在学习CUDA后补充<br>MIMD 两种常见类型 注意有多个处理单元即多个处理器 是异步的没有全局时钟 一个是共享内存系统，多个核共享一个内存系统，分布式内存系统，多个核——内存对。第一类具体有两个<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/UMA.png"                                     ><br>分布式 最常见的就是cluster集群 以太网连接的一组PC就是 而每一台本身可能是共享内存所以称为混合系统<br>互联网络，可以理解为连接结点的结构。性能依赖于信息读取传输，而这有由硬件的互联网络决定。<br>共享内存系统中有两个 总线bus和交叉开关矩阵crossbar容易理解总线结构简单固定 ，小规模时高效，当结点增多可能出现阻塞，抢夺，因为大小是固定的，无法调整。<br>CrossBar <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/Switch.png"                                     ><br>上图结构保证了不会出现信息覆盖<br>分布式网络互联结构 其实就是互联网本身的一些结构了<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/net.png"                                     ><br>带宽是衡量网络传输速度的，宽度就是讲网络划分为两部分最少的同时通信数量<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/net2.png"                                     ><br>延迟和带宽 两个指标<br>共享一致性问题以及解决方案 首先由于Cache 当一个x的内存值改变时，另一个核中cache里缓存的值可能没变。两种方法解决，监听总线和用目录记录。伪共享问题与cache 命中有关 尤其与cache大小有关 当一个核的工作区恰好覆盖一个缓存时，那么就会发生进程间跳跃地对缓存覆盖，最终其实没有共享，反而增加不命中率。<br>对于共享内存系统我们通常派生多线程，分布式我们派生多进程<br>SPMD 单程序多数据流 if(thread0&#x2F;process 0){}elif(1&#x2F;1){}的结构<br>共享内存中的问题：线程不确定性 通过 mutex 和 信号量来互斥实现 同时对于可重入函数的使用 对应的许多拥有static变量的函数就是线程不安全函数当多个线程调用时可能发生问题，解决方法可以是自己上锁或者调用对应库中的线程安全函数<br>分布式中的问题：最多的API就是解决消息传递的。而且其也可以在共享内存中使用，原理就是逻辑上讲共享空间分割为多个独立空间有点像虚拟空间的操作 通常这样的API包含一个send 一个recv函数 然后rank来唯一表示进程 然后缓冲区区分 然后0对应stdout 以及一些广播和归约函数，最常见API MPI message passing interface <br>输入输出问题 输入输出问题常常因为异步而具有不确定性这里有一些规范convention</font></strong></p><p><strong><font color=pink>习惯<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/convention.png"                                     >总结而言就是没有任何两个文件标识符在实际输入输出时交叉，各自分组线程独自管理<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/speedup.png"                                     >可扩展性 增加规模与同时增加核数线程数。效率不变<br>计时通常指程序开始到结束的时间</font></strong></p><p><strong><font color=Teal>并行程序设计步骤Foster方法<img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/fosterm.png"                                     >注意就是平均分配 同时要注意凝聚如果下一个依赖于上一个就可以凝聚为一个任务</font></strong></p><ul><li><p><strong><font color=lightyellow>MPI详解</font></strong></p><ul><li><font color=salmon><a class="link"   href="https://www.geeksforgeeks.org/creating-an-mpi-cluster/" >MPI集群的搭建方法 感觉mpi 也逐渐成为其他更高层计算框架实现的底层原理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></font></li><li><font color=yellow>通信子，通信子可以看作一组可以互相通信的进程，初始时有MPI创建了一组WORLD,可以创建多组。可以调用函数得知对应大小以及每一个的rank。</font></li><li><font color=yellow>Recv 与 Send函数的语义。各自有自己的缓冲区其实就是指定的存储区。tag用于互相匹配。有status结构来实际获取。匹配包括：同一个communicator，rank匹配。tag匹配。传输信息type匹配。接受去内存大于发送区。对于接受函数有两个宏量。MPI_ANY_SOURCE MPI_ANY_TAG 字面意思就是可以任意接受。发送没有 且一定要指定好comm</font></li><li><font color=yellow>MPI_Status参数获取实际传送的字节数。MPI_STATUS_IGNORE</font></li><li><font color=yellow>Send语义，可以阻塞，此时不返回。可以缓冲，放入内部存储器，然后返回。返回时并不知道是否成功发送。实际是如果发送信息小于默认的截止大小就缓存，否则就阻塞。Recv一定阻塞。可能出现悬挂</font></li><li><font color=yellow>前面的是点对点 还有可以广播的集合通有内置的操作和我们自定义的operator 同样的还有信息的传播 API</font></li><li><font color=yellow>线程可以理解为轻量级进程 一个正在运行的程序在一个处理器上的实例 编译器的话需要一个-lpthread 参数</font></li><li><font color=yellow>注意我们的这个全局变量需要定义在所有的函数外面然后 main 就是一个主线程</font></li><li><font color=orange>目前看来我们需要做到就是明白原理，然后学下具体的API  </font></li><li><font color=yellow></font></li><li><font color=yellow></font></li><li><font color=yellow></font></li><li><font color=yellow></font></li><li><font color=yellow></font></li></ul></li><li><p><font color=yellow></font></p><ul><li><font color=yellow></font></li><li><font color=yellow></font></li></ul></li></ul></li><li><h2 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a><font color=slateblue>CUDA</font></h2><ul><li><font color=slategrey>CPU 芯片，其实L3缓存占占据了最大的位置 <br>重要的任务就是判断是任务间是否独立 如果独立可能才可以分离task 就是指的一些指令和数据的集合<br>task parallelism 关注多核上的函数并行 data parallelism 关注多核上的数据并行 cuda、主要解决data parallelism <br>核利用率的问题</font></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;计算机科学中的自然原理&quot;&gt;&lt;a href=&quot;#计算机科学中的自然原理&quot; class=&quot;headerlink&quot; title=&quot;计算机科学中的自然原理&quot;&gt;&lt;/a&gt;计算机科学中的自然原理&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; cl</summary>
      
    
    
    
    
    <category term="自然" scheme="https://spikeihg.github.io/tags/%E8%87%AA%E7%84%B6/"/>
    
  </entry>
  
  <entry>
    <title>Parallel-Programming</title>
    <link href="https://spikeihg.github.io/2023/10/12/Parallel-Programming/"/>
    <id>https://spikeihg.github.io/2023/10/12/Parallel-Programming/</id>
    <published>2023-10-12T09:07:24.000Z</published>
    <updated>2023-10-21T04:29:06.691Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HPC-Parallel-Programming、"><a href="#HPC-Parallel-Programming、" class="headerlink" title="HPC - Parallel-Programming、"></a>HPC - Parallel-Programming、</h3><h3 id="重大发现就是我们的这个触摸板-可以做到切换-多个手指同时下滑-就可以显示桌面-左右滑动就可以实现-alt-的切换功能-然后还有就是-f11-对于我们的网页-也可以进行全屏显示-f12-进行监测-同时-还可以触摸屏左右两指滑动进行返回前进历史返回-发现一个巨大的新东西就是我们使用两个手指左右滑动是历史前进后退-使用三个手指是alt功能-使用四个手指是windows桌面切换-还有一个就是-ctrl-e-时搜索url框"><a href="#重大发现就是我们的这个触摸板-可以做到切换-多个手指同时下滑-就可以显示桌面-左右滑动就可以实现-alt-的切换功能-然后还有就是-f11-对于我们的网页-也可以进行全屏显示-f12-进行监测-同时-还可以触摸屏左右两指滑动进行返回前进历史返回-发现一个巨大的新东西就是我们使用两个手指左右滑动是历史前进后退-使用三个手指是alt功能-使用四个手指是windows桌面切换-还有一个就是-ctrl-e-时搜索url框" class="headerlink" title="重大发现就是我们的这个触摸板 可以做到切换 多个手指同时下滑 就可以显示桌面 左右滑动就可以实现 alt 的切换功能 然后还有就是 f11 对于我们的网页 也可以进行全屏显示 f12 进行监测 同时 还可以触摸屏左右两指滑动进行返回前进历史返回 发现一个巨大的新东西就是我们使用两个手指左右滑动是历史前进后退 使用三个手指是alt功能 使用四个手指是windows桌面切换 还有一个就是 ctrl + e 时搜索url框"></a><font color=pink>重大发现就是我们的这个触摸板 可以做到切换 多个手指同时下滑 就可以显示桌面 左右滑动就可以实现 alt 的切换功能 然后还有就是 f11 对于我们的网页 也可以进行全屏显示 f12 进行监测 同时 还可以触摸屏左右两指滑动进行返回前进历史返回 发现一个巨大的新东西就是我们使用两个手指左右滑动是历史前进后退 使用三个手指是alt功能 使用四个手指是windows桌面切换 <br>还有一个就是 ctrl + e 时搜索url框</font></h3><ol><li><h3 id="并行程序设计入门开始"><a href="#并行程序设计入门开始" class="headerlink" title="并行程序设计入门开始"></a><font color=seablue>并行程序设计入门开始</font></h3><ol><li><strong><a class="link"   href="https://heptagonhust.github.io/HPC-roadmap/" >RoadMap <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>来自七边形</strong></li><li><em><strong>这里文件<a href="/doc/%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%AF%BC%E8%AE%BA.pdf">并行设计</a></strong></em></li><li><strong><a class="link"   href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" >Nvidia cuda guidance <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></li><li><em><strong>MPI<a class="link"   href="https://www.netlib.org/utk/papers/mpi-book/mpi-book.html" >tutorial <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></em></li><li>MPI<a class="link"   href="https://mpitutorial.com/tutorials/mpi-introduction/" >manual <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link"   href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#optimizing-cuda-applications" >nvidia <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><font color=violet>下载了几个nvidia的的samples在happyplace&#x2F;0a 里面 可以make一下</font></li><li></li><li><em><strong>这里保存几个markdown的颜色</strong></em></li></ol><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ee1.png"                                     ></p></li></ol><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ee2.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ee3.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ee4.png"                                     ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/ee5.png"                                     ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;HPC-Parallel-Programming、&quot;&gt;&lt;a href=&quot;#HPC-Parallel-Programming、&quot; class=&quot;headerlink&quot; title=&quot;HPC - Parallel-Programming、&quot;&gt;&lt;/a&gt;HPC - Par</summary>
      
    
    
    
    
    <category term="HPC" scheme="https://spikeihg.github.io/tags/HPC/"/>
    
  </entry>
  
  <entry>
    <title>逻辑电路/c++</title>
    <link href="https://spikeihg.github.io/2023/10/11/%E9%80%BB%E8%BE%91%E7%94%B5%E8%B7%AF/"/>
    <id>https://spikeihg.github.io/2023/10/11/%E9%80%BB%E8%BE%91%E7%94%B5%E8%B7%AF/</id>
    <published>2023-10-11T12:15:48.000Z</published>
    <updated>2023-12-18T10:52:31.973Z</updated>
    
    <content type="html"><![CDATA[<h3 id="大爱逻辑电路，简洁是美的灵魂"><a href="#大爱逻辑电路，简洁是美的灵魂" class="headerlink" title="大爱逻辑电路，简洁是美的灵魂"></a><font color=pink>大爱逻辑电路，简洁是美的灵魂</font></h3><ul><li><h2 id="My-Efficient-c-想不到吧"><a href="#My-Efficient-c-想不到吧" class="headerlink" title="My Efficient c ++ (想不到吧)"></a><font color=deepskyblue>My Efficient c ++ (想不到吧)</font></h2><p><font color=salmon>同时，我觉得既然是总结，咱们就换一种视角串联整个c ++ 知识点。</font></p></li><li><p><font color=pink>模板</font></p><p><font color=lightgreen>模板推断，也就是实例化是编译器的工作。理解实例化，只有实际调用或者是定义时才会实例化。并且不同实例的函数或者类是独立的。同时模板定义一般写在头文件里面。class 和 typename 是相同的含义。模板具有默认类型参数，所以平时看定义的时候注意一下</font></p><div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> N,<span class="type">unsigned</span> M&gt; <span class="built_in">compare</span>(<span class="built_in">char</span> (&amp;a)[N],<span class="built_in">char</span> (&amp;b)[M]);<span class="comment">// 非类型实参</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> F=less&lt;T&gt;&gt;<span class="type">int</span> <span class="built_in">compare</span>(<span class="type">const</span> T&amp;v1,<span class="type">const</span> T&amp;v2,F f=<span class="built_in">F</span>());</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>=<span class="type">int</span>&gt; <span class="keyword">class</span> Numbers&#123;&#125;;</span><br><span class="line">Numbers &lt;&gt; b; <span class="comment">// 使用默认参数 任何时候&lt;&gt;都不能省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Debugdelete</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;<span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(T*p)</span><span class="type">const</span></span>&#123;<span class="keyword">delete</span> p;&#125;<span class="comment">// 之所以有const的原因是const保护的是删除器的成员，区分清楚保护的对象 p 是外来的</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">Debugdelete</span>()(); <span class="comment">//在一个临时对象上调用operator()</span></span><br><span class="line"><span class="function">unique_ptr&lt;<span class="type">int</span>,Debugdelete&gt; <span class="title">ptr</span><span class="params">(<span class="keyword">new</span> <span class="type">int</span>,Debugdelete())</span></span>; <span class="comment">// 这里可以窥见删除器的本质就是一个可调用对象，这是一个简洁而深刻的概念 全新的 这是常见的用法</span></span><br><span class="line"><span class="function">unique_ptr&lt;<span class="type">int</span>, <span class="title">decltype</span><span class="params">(compareIntfunction)</span>*&gt; <span class="title">ptr2</span><span class="params">(<span class="keyword">new</span> <span class="type">int</span> ,compareIntfunction)</span></span>; <span class="comment">// 类似的 具体原理就是指针调用析构函数时会是使用删除器</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">check</span><span class="params">(size_type i,<span class="type">const</span> std::string &amp; msg)</span><span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">if</span>(i&gt;=data-&gt;<span class="built_in">size</span>())</span><br><span class="line">    <span class="keyword">throw</span> std::<span class="built_in">out_of_range</span>(msg);&#125;<span class="comment">// 这个工厂函数写得很好！！！</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div></li></ul><div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">A</span>&#123;</span><br><span class="line">      <span class="keyword">template</span>&lt;<span class="keyword">typename</span> It&gt;<span class="built_in">A</span>(It b,Ite);</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> It&gt;</span><br><span class="line">  A&lt;T&gt;::<span class="built_in">A</span>(It b,It e):<span class="built_in">data</span>(make_shared&lt;std::vector&lt;T&gt;&gt;(b,e))&#123;&#125;</span><br></pre></td></tr></table></figure></div><ul><li><p><font color=violet>类模板的成员模板</font></p><p><font color=violet>正是依靠这个实现迭代器构造函数.——一个问题，由于实例化时，每一个独立的源文件都需要一份实例，可能存在重复的性能消耗，所以我们可以显示控制实例化 extern 声明一个具体的类型参数的模板，然后必须在某一文件里有定义 template 开始。最后记得链接在一起。定义其实也就是一句话，对于类模板来说这会使得所有成员都实例化，这点注意哦<br>这里也有一个有趣的问题就是shared_ptr 与 unique_ptr 删除器的实现方式。shared_ptr 可以随时reset 改变删除器所以实际是将删除器作为成员保存，指针形式保存，析构时大概就是 del? del(p): delete p; 而 unique_ptr 只允许定义时传入作为模板参数，所以就是编译时绑定效率更高，但是不能任意改变。</font></p></li><li><p><font color=yellow>异常处理</font></p><p><font color=cornsilk>异常处理包含两个过程，异常捕获和异常处理。捕获依靠throw 表达式，处理依靠try catch 语句块。 注意想要被catch 捕获需要使用try 存在 try 的多重嵌套，依照调用链反向寻找所有层次的catch 语句直到匹配，如果一个都不匹配则terminate直接终止。有一些标准库定义的错误类，有些需要初始化const char[]。 .what()方法可以查看字符串内容 栈展开其实就是。 展开过程会销毁对象，依照局部对象的销毁原则。<br>异常对象可以是标准库定义，也可以自己定义，完全类型有可访问的析构与构造函数，同时如果在throw 语句中解引用指针，如果是一个派生对象，基类指针则抛出的部分只有其基类的部分</font></p></li><li><p><font color=cyan>随机数</font></p><p><font color=lightgreen>随机数使用，包含两个部分，一个部分是随机数引擎，另一个是随机数分布。引擎生成一系列unsigned ，分布完成我们的需求生成所需的指定类型给定范围，满足特定概率分布的随机数 。引擎需要种子，否则也是固定的伪随机 ,default_random_engine 其实是系统预定义的最佳引擎，具体有三个。然后分布种类是模板，需要指定类型别名。调用的方法类似 u(e) 。 u是分布种类。 e 是对象。</font></p></li><li><p><font color=salmon>5G555 多谐振荡器 产生脉冲</font></p></li><li><h2 id="数字电路要义"><a href="#数字电路要义" class="headerlink" title="数字电路要义"></a><font color=pink>数字电路要义</font></h2><ul><li><p><font color=lightgreen>逻辑函数</font></p><p>使用与非门来建立所有三种逻辑门，实现电路的统一。异或可以用于奇偶校验 奇数个变量为1 结果就是1 偶数个为0  对偶函数就是0 1 也要互换记得和反演一样 同或就相反  与或表达式就是先与后或 区别最小项最大项的方法 就是 最小项之和 最大项之积<br>卡诺图注意最小项在图中对应的顺序 卡诺图中每个圈至少需要一个一个独立 的1（最小项）</p></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;大爱逻辑电路，简洁是美的灵魂&quot;&gt;&lt;a href=&quot;#大爱逻辑电路，简洁是美的灵魂&quot; class=&quot;headerlink&quot; title=&quot;大爱逻辑电路，简洁是美的灵魂&quot;&gt;&lt;/a&gt;&lt;font color=pink&gt;大爱逻辑电路，简洁是美的灵魂&lt;/font&gt;&lt;/h3&gt;&lt;</summary>
      
    
    
    
    
    <category term="计算机组成原理" scheme="https://spikeihg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>BombLab</title>
    <link href="https://spikeihg.github.io/2023/10/07/BombLab/"/>
    <id>https://spikeihg.github.io/2023/10/07/BombLab/</id>
    <published>2023-10-07T11:36:16.000Z</published>
    <updated>2023-11-23T08:28:14.968Z</updated>
    
    <content type="html"><![CDATA[<h3 id="血淋淋的教训啊-关bash的时候一起关了-直接没保存-全部没了-😫"><a href="#血淋淋的教训啊-关bash的时候一起关了-直接没保存-全部没了-😫" class="headerlink" title="血淋淋的教训啊 关bash的时候一起关了 直接没保存 全部没了 😫"></a><font color=pink>血淋淋的教训啊 关bash的时候一起关了 直接没保存 全部没了 😫</font></h3><ul><li><h2 id="离散有趣知识点"><a href="#离散有趣知识点" class="headerlink" title="离散有趣知识点"></a><font color=lightgreen>离散有趣知识点</font></h2><p><font color=orange>离散马上要结课了，里面很多还是很有趣的，这里就零散记载一些有趣或者是有用的知识点</font></p></li><li><p>析取是或者，合取是与。蕴含命题就是条件语句。逆否等价于原来的条件语句。 p仅当q等价于p-&gt;q。也就是等价于如果p则q 将命题用于语句翻译可以简化原理。常见的等价式子以及德摩根定律。</p></li><li><p>合取范式，析取范式，可满足问题，数独。极大项，极小项。极大项与极小项的关系就是取反。注意规定的真值不同，极小项是合取，使式子为真，极大项是析取，使得式子为假 主析取范式，主合取范式就是每一项是极大（小）项 求主析取范式 主析取范式和住合取范式下标是互补的</p></li><li><p>谓词就是形容词 函数 量词就是全称存在 唯一性量词</p></li><li><p>量词的否定 嵌套量词的否定就是移动否定就可以了连续移动 条件语句和量词组合 不能分发</p></li><li><p>归谬法似乎是将需要证明的结论的反命题作为前提引入，然后根据所有前提得到一个a^~a 的情况 </p></li><li><p>而反证法 是这样 我们要证明 p -&gt; q ,那么我们可以证明其等价的逆否命题， ~q -&gt; ~p 这样来得到原命题成立</p></li><li><p>归谬证明法 就是通过 得到<del>p -&gt; (r^</del>r) 这样的式子为真 然后得到 p 为真，一般就是一个命题 p 而不是条件语句 条件语句的证明需要假设p,<del>q 然后得到 ~p ，p; q,</del>q 两组矛盾式得到其中一组即可</p></li><li><p>直接证明 反正法 归谬证明</p></li><li><p>鸽巢原理 鸽巢原理注意实际应用 找到什么是盒子 什么是物品 </p></li><li><p>排列和组合</p></li><li><p>环排列需要除以环中的元素数量</p></li><li><p>很多组合恒等式可以通过建模，运用一种组合场景来进行证明</p></li><li><p>范德蒙德恒等式 挺有用的 也挺好理解 变形</p></li><li><p>重复排列的问题 就是平方 组合就稍微复杂</p></li><li><p>递推关系式 求解 就是一个特解组合上一个伴随解</p></li><li><p>递推关系的寻找  本事是寻找当前问题能不能由子问题或者说是先前状态转换而来。</p></li><li><p>目前我的理解中生成函数的使用图景并不是很多 目前有一个就是求解计数问题。 生成函数还可以求解递推关系</p></li><li><p>容斥原理</p></li><li><p>容斥原理 公式里面的加减是交替的 并且肯定显然从 加法开始</p></li><li><p>容斥原理配合组合数来使用</p></li><li><p>容斥原理求解映上函数 这个其实可以单独抽象成一个标准模型 成为许多问题的解决的原理 而且这种模型如果直接求解很容易出现问题 重复求解</p></li><li><p>限制条件可以考虑求全部情况 然后减去互斥的情况</p></li><li><p>模运算 有同余恒等式 满足加或者乘法的运算律</p></li><li><p>求模运算得到的结果始终是正值 计算被模的数是负数</p></li><li><p>模指数运算 二进制转换指数 然后每算一项都模一次</p></li><li><p>gcd 欧几里得算法 裴树算法可以用来证明一些等式</p></li><li><p>ab mod m&#x3D;amod m b mod m</p></li><li><p>求模的逆 运用欧几里得算法 就是求贝祖系数</p></li><li><p>求解线性同余式的方法就是运用欧几里得算法求出逆 而逆其实就是求解 贝祖系数 对了还有一个前提就是 a 与 m要满足互素 但是即使不互素 满足一定条件就可以求解</p></li><li><p>中国剩余定理 求解线性同余方程组的一种方法 原理同上 然后就是类似的一种叫做反向替代的方法</p></li><li><p>费马小定理 用来求解整数模指数运算</p></li><li><p>原根和离散对数 是一些密码学的基础</p></li><li><p>费马小定理的推广 欧拉函数和欧拉定理 勤奋的欧拉哈哈哈哈哈</p></li><li><p>RSA 的原理 凯撒加密加三模26移位密码 移位数k就是密钥 仿射密码求解的关键就是求同余方程</p></li><li></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;血淋淋的教训啊-关bash的时候一起关了-直接没保存-全部没了-😫&quot;&gt;&lt;a href=&quot;#血淋淋的教训啊-关bash的时候一起关了-直接没保存-全部没了-😫&quot; class=&quot;headerlink&quot; title=&quot;血淋淋的教训啊 关bash的时候一起关了 直接没</summary>
      
    
    
    
    
    <category term="LINUX" scheme="https://spikeihg.github.io/tags/LINUX/"/>
    
  </entry>
  
  <entry>
    <title>TLCL@3</title>
    <link href="https://spikeihg.github.io/2023/10/04/TLCL-3/"/>
    <id>https://spikeihg.github.io/2023/10/04/TLCL-3/</id>
    <published>2023-10-04T09:48:31.000Z</published>
    <updated>2023-12-07T09:32:44.310Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TLCL-chapter-3"><a href="#TLCL-chapter-3" class="headerlink" title="TLCL chapter 3"></a>TLCL chapter 3</h2><h3 id="GOOOOOOOOOOOOOOD-解决了上传静态文件的-问题-在markdown里面变成-download-images-file-normal-pdf"><a href="#GOOOOOOOOOOOOOOD-解决了上传静态文件的-问题-在markdown里面变成-download-images-file-normal-pdf" class="headerlink" title="GOOOOOOOOOOOOOOD 解决了上传静态文件的 问题 在markdown里面变成 [download](\..\images\file\normal.pdf)"></a><font color=pink>GOOOOOOOOOOOOOOD 解决了上传静态文件的 问题 在markdown里面变成 [download](\..\images\file\normal.pdf)</font></h3><ul><li><h3 id="发现一个很妙的事就是分屏可以将鼠标与键盘控制分开很适合边看边写笔记"><a href="#发现一个很妙的事就是分屏可以将鼠标与键盘控制分开很适合边看边写笔记" class="headerlink" title="发现一个很妙的事就是分屏可以将鼠标与键盘控制分开很适合边看边写笔记"></a><font color=aqua>发现一个很妙的事就是分屏可以将鼠标与键盘控制分开很适合边看边写笔记</font></h3></li><li><p>#<font color=yellow>我是真的有病 注意更改 .bashrc 文件之前要保存一下原有配置</font></p></li><li><h2 id="Cmake-and-Makefile"><a href="#Cmake-and-Makefile" class="headerlink" title="Cmake and Makefile"></a><font color=salmon>Cmake and Makefile</font></h2><ul><li>export PATH&#x3D;”$PATH:&#x2F;usr&#x2F;bin”注意规范 前面没有$</li></ul></li><li><h3 id="文件操作here"><a href="#文件操作here" class="headerlink" title="文件操作here"></a>文件操作<a class="link"   href="http://billie66.github.io/TLCL/book/chap16.html" >here <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h3><ul><li>设计很多底层硬件，由于wsl与虚拟机文件差别较大暂时skip read</li></ul></li><li><h3 id="网络葵花宝典下载"><a href="#网络葵花宝典下载" class="headerlink" title="网络葵花宝典下载"></a>网络<a href="/doc/%E8%91%B5%E8%8A%B1%E5%AE%9D%E5%85%B8.pdf">葵花宝典下载</a></h3><ul><li>netstat 指令</li><li>ftp指令</li><li>telnet指令 都是可以直接使用相关协议</li><li>ftp lftp都可以下载文件</li><li><em><strong><font color=pink>wget指令直接下载界面 可行男泵</font></strong></em></li></ul></li><li><h3 id="SSH-secure-shell"><a href="#SSH-secure-shell" class="headerlink" title="SSH secure shell"></a>SSH secure shell</h3><ul><li><strong>这是一个协议 port number22</strong></li><li><strong><a class="link"   href="https://phoenixnap.com/kb/ssh-to-connect-to-remote-server-linux-or-windows#:~:text=Open%20the%20terminal%20on%20the,ssh%20localhost%20and%20hit%20enter." >一个sshlocalhost教程 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></li><li><strong>最近ssh遇到很多问题这里集中总结一下</strong><ul><li><strong>关于启动服务器<a class="link"   href="https://askubuntu.com/questions/1379425/system-has-not-been-booted-with-systemd-as-init-system-pid-1-cant-operate" > <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> <br><font color=red> sudo service ssh restart 这个命令有作用 类似的还有 sudo service ssh status 关键就是 service 操作具体可见tldr service</font></strong></li></ul></li></ul></li><li><h3 id="locate-amp-find"><a href="#locate-amp-find" class="headerlink" title="locate &amp; find"></a>locate &amp; find</h3><ul><li><em><strong><font color=pink>我是真的有病，又一次忘记保存全部没了</font></strong></em></li><li><img                       lazyload                     src="/images/loading.svg"                     data-src="D:\github.1.0\My_blog_hexo\source\images\tests.png"                                     ></li></ul></li><li><p><img                       lazyload                     src="/images/loading.svg"                     data-src="D:\github.1.0\My_blog_hexo\source\images\lo.png"                                     ></p><ul><li><p><strong>注意可以进行执行自己的操作 -exec cmd ‘{}’ ‘;’ 注意 {} ； 必不可少 {} 代表的是当前路径 ； 代表命令的结束 要引用起来 因为都是特殊涵义的字符 可以用+ 这样就是全部执行 而不是每次都执行一次 同时可以用-ok 指令代替我们的-exec 这样每次都会进行一下询问 ！！！！</strong></p></li><li><p><strong><font color=green>压缩文件</font></strong></p><ul><li><em><strong>gzip and gunzip</strong></em></li><li><em><strong>gzip + file 注意没有中间选项 此时是原始文件 但是可以对一压缩的文件进行选项查看</strong></em></li><li><em><strong>gunzip -c file.gz 查看压缩文件的内容</strong></em></li><li><em><strong>bzip2 也是一个类似于 gzip的命令 压缩程度更高 gzip -d 就相当于解压缩了</strong></em></li></ul></li><li><p><strong><font color=blue>归档文件 archiving !!!!</font></strong></p><ul><li><strong>tar tape archive 备份归档 一组独立的文件或者几个目录 或者两者兼有 通常后缀 为.tar h或者 .tgz 表示 gzip压缩过的归档包</strong></li><li><strong>四个模式 注意先写模式 再写选项</strong></li><li><strong>cf czf 都是创建 tvf 列举查看 xf xvf 就是复原 注意路径名格式</strong></li><li><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/tar.png"                                     ></li><li><em><strong>zip unzip 与tar和gzip的结合  类似 但是更多用于 与windows交互</strong></em></li></ul></li><li><p><em><strong>同步<a class="link"   href="http://billie66.github.io/TLCL/book/chap19.html" >可以看看但是似乎目前用的不多 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></em></p></li><li><p><em><strong><font color=pink>中间暂时跳过了文本处理和正则来个比较重要的make</font></strong></em></p><ul><li>脚本语言不需要编译 而是直接执行 例如 shell脚本 python PHP perl ruby</li><li>tar tzvf tarfile | head — 检查指令</li><li>通过这个可以看到一些标准版本源代码的组织形式 其中有一些大写的如README INSTALL 等介绍文件 同时 还有configure文件用于 配置的 同时就是各种头文件和源文件</li><li><em><strong><font color=red>系统的源码通常维护再&#x2F;usr&#x2F;src 中 供多个用户试用的源码通常再&#x2F;usr&#x2F;local&#x2F;src 中</font></strong></em></li><li>构建通常两步 .&#x2F;configure make</li><li>.&#x2F;configure 主要配置相关的需要的环境和依赖项同时创建makefile</li><li>sudo make install 对于一些包装良好的库 可以直接执行此命令安装成功</li></ul></li><li><p><em><strong><font color=pink>LINUX小子第二步——Shell脚本</font></strong></em></p><ul><li>编写脚本三步</li><li><em><strong>写一个脚本</strong></em></li><li><em><strong>让其可执行 chomod 755 file 对所有人都可执行 700只有拥有者可以执行</strong></em></li><li><em><strong>放在一个shell能找到的位置 配置PATH 这个原理就是对于可执行文件 如果直接输入名字 shell会在环境变量的path路径中寻找 因此对于通常自己的没有位于相关路径的脚本是找不到的所以需要文件路径通常我们使用相对路径 .&#x2F;prog</strong></em></li></ul></li><li><p><em><strong><font color=green>安装chrome成功 还得是微软教程但是有乱码的问题同时除了搜索以为ia其他时候都很慢</font></strong></em></p></li><li><p><em><strong><font color=green>Good 现在查看html文件就直接google-chrome + 文件路径</font></strong></em></p></li><li><h3 id="脚本编写"><a href="#脚本编写" class="headerlink" title="脚本编写"></a><font color=blue>脚本编写</font></h3><ul><li><em><strong>注意通常而言在脚本里面 全大写代表常量 小写代表变量</strong></em></li><li><em><strong>一定要正确的书写变量名 在命令行内也可以直接进行变量使用 不需要提前声明 declare -r TITLE 强制命令常量</strong></em></li><li><em><strong>变量名展开的几种形式</strong></em></li><li><img src="/../images/vara.png" alt="../images/vara.png"></li><li><em><strong><font color =red>还有一种高级的操作叫作 here document <img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/here.png"                                     ></font></strong></em></li><li><em><strong>shell函数</strong></em><ul><li>function name{} &#x2F; name(){}两种</li><li>先定义在使用 return语句控制权</li><li>局部变量在内部</li><li>定义方式 local var eg local foo foo&#x3D;0 外部不存在</li><li>完全可以用脚本函数 直接写道 .bashrc中 来代替别名</li></ul></li><li><strong>分支控制</strong><ul><li>$? 检测最近的一个指令执行退出情况 0为成功</li><li>上述的这个正是if控制实现的底层原理</li><li>格式就是if cmd;the cmd; fi 可以借[elif]<ul><li>还有各种文件比较操作<a class="link"   href="http://billie66.github.io/TLCL/book/chap28.html" >逆天 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li>通常是if [expression]</li></ul></li></ul></li></ul></li><li><p><font color=MediumSpringGreen>Df -h 指令 查看所有磁盘情况 不错的指令</font></p></li><li><p><strong><font color=cornsilk>su -l usrname    alt+n &#x2F;p 历史命令搜索  tar xvf 提取 gpg 一种内置的加密程序 gpg –verify gpg –recv-keys  gpg–fingerprint etc.</font></strong></p></li><li><p><strong><font color=cornsilk>今天遇到了实际很多会是链接的问题需要文件夹而非可执行文件的问题 JAVA_HOME 还有就是 wget 真方便 然后需要检查是不是一个tgz 可恶哩</font></strong></p></li><li><p><strong><font color=pink>export PATH&#x3D;~&#x2F;bin:”$PATH”类似的命令记住了</font></strong></p></li><li><p><strong><font color=cornsilk>. .bashrc 激活注意  每次修改环境变量时都要激活一下</font></strong></p></li><li><p><strong><font color=cornsilk>issu 解决 sudo usermod –append –group sudo &lt;username&gt; 就可以加权限了 </font></strong></p></li><li><p>sudo useradd </p></li><li><p><strong><font color=cornsilk>ssh 问题解决历程目前还没解决 10&#x2F;31 <a class="link"   href="https://www.hanselman.com/blog/how-to-ssh-into-wsl2-on-windows-10-from-an-external-machine" >port forwarding <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="https://superuser.com/questions/571196/port-forwarding-to-a-vmware-workstation-virtual-machine#:~:text=On%20Windows%2C%20you%20can%20access,setup%20on%20a%20typical%20router." >port forwarding in vmware <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="https://www.tutorialspoint.com/hadoop/hadoop_multi_node_clust" >hadoop manual <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br></font></strong></p></li></ul></li><li><h2 id="更多键盘操作"><a href="#更多键盘操作" class="headerlink" title="更多键盘操作"></a><font color=aqua><a class="link"   href="https://stackoverflow.com/questions/9679776/how-do-i-clear-delete-the-current-line-in-terminal" >更多键盘操作 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></font></h2></li><li><p>ctrl + u 删除当前行（命令）</p></li><li><p><font color=maroon>注意 git clone 最后在url后面加一个.<font color=blue>git</font></font></p></li><li><p><font color=cyan>deb 有统一的包管理所以可能下载安装更见简单 有内置命令来解决   runfile 通常是脚本完成</font></p></li><li><h2 id="apt-对于终端用户更加友好-相当于一个集合-集合很多命令的东西-然后就是apt-get-更加底层-有"><a href="#apt-对于终端用户更加友好-相当于一个集合-集合很多命令的东西-然后就是apt-get-更加底层-有" class="headerlink" title="apt 对于终端用户更加友好 相当于一个集合 集合很多命令的东西 然后就是apt-get 更加底层 有"></a><font color=pink>apt 对于终端用户更加友好 相当于一个集合 集合很多命令的东西 然后就是apt-get 更加底层 有</font></h2></li><li><h2 id="sudo-apt-get-autoremove-这是一个安全的指令用来-clean-you-system-没事就可以输入一下-原理就是清楚不再被任何应用使用的依赖-lib-stackoverflow-上面似乎还有一些其他工具可以-但是目前-这个命令就可以了"><a href="#sudo-apt-get-autoremove-这是一个安全的指令用来-clean-you-system-没事就可以输入一下-原理就是清楚不再被任何应用使用的依赖-lib-stackoverflow-上面似乎还有一些其他工具可以-但是目前-这个命令就可以了" class="headerlink" title="sudo apt-get autoremove 这是一个安全的指令用来 clean you system  没事就可以输入一下 原理就是清楚不再被任何应用使用的依赖 lib !!!! stackoverflow 上面似乎还有一些其他工具可以 但是目前 这个命令就可以了"></a><font color=yellow>sudo apt-get autoremove 这是一个安全的指令用来 clean you system  没事就可以输入一下 原理就是清楚不再被任何应用使用的依赖 lib !!!! stackoverflow 上面似乎还有一些其他工具可以 但是目前 这个命令就可以了</font></h2></li><li><p><font color=green>非登录就是不需要输入用户和密码 echo $0 查看 如果是-bash  就是登录 bash 就是非登录 主要区别就在于载入相关启动文件</font></p></li><li><p>cat -n </p></li><li><p>power9 是一个超级电脑的架构流式处理器</p></li><li><p>expansion 尤其是 brace expansion 还有 quoting 引用就是 “” ‘’</p></li><li><h2 id="root-开机自启项和sysmecl"><a href="#root-开机自启项和sysmecl" class="headerlink" title="root 开机自启项和sysmecl"></a><a class="link"   href="https://learn.microsoft.com/en-us/windows/wsl/wsl-config" >root 开机自启项和sysmecl <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h2></li><li><p>rm -r删除非空文件夹 rmdir rm -d删除空文件夹</p></li><li><p>descend into directory 就是问是否同时删除里面的文件 yes即可 但是这首会一个一个出现 所以最好还是不要-i当文件很多的时候</p></li></ul><h2 id="真的不好说-autoremove-把我mpi删了-乐！！！"><a href="#真的不好说-autoremove-把我mpi删了-乐！！！" class="headerlink" title="真的不好说 autoremove 把我mpi删了 乐！！！"></a><strong><font color=red>真的不好说 autoremove 把我mpi删了 乐！！！</font></strong></h2><ul><li><p><font color=pink>ssh passphrase 我的同样的通用密码</font></p></li><li><p><a class="link"   href="https://www.strongdm.com/blog/ssh-passwordless-login" >ssh passwordless <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></li><li><p><font color=orange>who指令可以查看其他用户在本机的使用情况。注意理解 linux 是一个多用户多任务的操作系统。而windows 是一个单用户假多任务的操作系统</font></p></li><li><p>useradd 添加用户 但是没有提示 userdel 删除用户</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;TLCL-chapter-3&quot;&gt;&lt;a href=&quot;#TLCL-chapter-3&quot; class=&quot;headerlink&quot; title=&quot;TLCL chapter 3&quot;&gt;&lt;/a&gt;TLCL chapter 3&lt;/h2&gt;&lt;h3 id=&quot;GOOOOOOOOOOOOOOD-</summary>
      
    
    
    
    
    <category term="LINUX" scheme="https://spikeihg.github.io/tags/LINUX/"/>
    
  </entry>
  
  <entry>
    <title>signature</title>
    <link href="https://spikeihg.github.io/2023/10/02/signature/"/>
    <id>https://spikeihg.github.io/2023/10/02/signature/</id>
    <published>2023-10-02T09:15:59.000Z</published>
    <updated>2023-10-03T03:03:01.048Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ps了一个签名方便以后用"><a href="#ps了一个签名方便以后用" class="headerlink" title="ps了一个签名方便以后用"></a><font color=pink>ps了一个签名方便以后用</font></h2><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/%E7%AD%BE%E5%90%8D.png"                      alt="我的签名"                ></p><blockquote><p>你别说有点书法的感觉 哈哈哈哈哈！</p></blockquote><h3 id="还是应该记录下方法-ps-魔棒选择-每次扣几笔然后ctrl-c-ctrlv-复制一个图层-最后合并可见图层"><a href="#还是应该记录下方法-ps-魔棒选择-每次扣几笔然后ctrl-c-ctrlv-复制一个图层-最后合并可见图层" class="headerlink" title="还是应该记录下方法 ps 魔棒选择 每次扣几笔然后ctrl c ctrlv 复制一个图层 最后合并可见图层"></a><font color=pink>还是应该记录下方法 ps 魔棒选择 每次扣几笔然后ctrl c ctrlv 复制一个图层 最后合并可见图层</font></h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ps了一个签名方便以后用&quot;&gt;&lt;a href=&quot;#ps了一个签名方便以后用&quot; class=&quot;headerlink&quot; title=&quot;ps了一个签名方便以后用&quot;&gt;&lt;/a&gt;&lt;font color=pink&gt;ps了一个签名方便以后用&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;&lt;img  </summary>
      
    
    
    
    
    <category term="signature" scheme="https://spikeihg.github.io/tags/signature/"/>
    
  </entry>
  
  <entry>
    <title>TLCL@2</title>
    <link href="https://spikeihg.github.io/2023/09/30/TLCL-2/"/>
    <id>https://spikeihg.github.io/2023/09/30/TLCL-2/</id>
    <published>2023-09-30T02:56:45.000Z</published>
    <updated>2023-10-03T12:23:07.832Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TLCL"><a href="#TLCL" class="headerlink" title="TLCL"></a>TLCL</h2><blockquote><p>新的开始 </p></blockquote><h4 id="今天怒创了两个用户-密码都是老密码alt-t-google-translate-x2F-the-search-box-alt-left-ctrl-shift-aalt-左右键是返回上一个页面-ctrl-tab-下一个标签-ctrl-shift-tab-上一个"><a href="#今天怒创了两个用户-密码都是老密码alt-t-google-translate-x2F-the-search-box-alt-left-ctrl-shift-aalt-左右键是返回上一个页面-ctrl-tab-下一个标签-ctrl-shift-tab-上一个" class="headerlink" title="今天怒创了两个用户 密码都是老密码alt t google translate &#x2F; the search box alt left   ctrl shift aalt 左右键是返回上一个页面 ctrl tab 下一个标签 ctrl shift tab 上一个 "></a><font color=aqua>今天怒创了两个用户 密码都是老密码<br>alt t google translate &#x2F; the search box alt left   ctrl shift a<br>alt 左右键是返回上一个页面 ctrl tab 下一个标签 ctrl shift tab 上一个 </font></h4><h3 id="发现两个有用的东西-google搜索栏使用小数字键盘的上下键可以查看推荐搜索-然后就是cmd中打开md-x2F-example-md-键入就可以-原来要运行可运行文件要在前面加上一个-x2F"><a href="#发现两个有用的东西-google搜索栏使用小数字键盘的上下键可以查看推荐搜索-然后就是cmd中打开md-x2F-example-md-键入就可以-原来要运行可运行文件要在前面加上一个-x2F" class="headerlink" title="发现两个有用的东西 google搜索栏使用小数字键盘的上下键可以查看推荐搜索 然后就是cmd中打开md .&#x2F;example.md 键入就可以 原来要运行可运行文件要在前面加上一个.&#x2F;"></a><font color=pink>发现两个有用的东西 google搜索栏使用小数字键盘的上下键可以查看推荐搜索 然后就是cmd中打开md .&#x2F;example.md 键入就可以 原来要运行可运行文件要在前面加上一个.&#x2F;</font></h3><h4 id="command-syntaxsyntax2syntax3q-amp-a"><a href="#command-syntaxsyntax2syntax3q-amp-a" class="headerlink" title="command syntaxsyntax2syntax3q&amp;a"></a><font color=seagreen><a class="link"   href="https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/command-line-syntax-key" >command syntax <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="http://docopt.org/" >syntax2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html#tag_12_01" >syntax3 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="https://stackoverflow.com/questions/9725675/is-there-a-standard-format-for-command-line-shell-help-text" >q&amp;a <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></font></h4><h3 id="键盘操作"><a href="#键盘操作" class="headerlink" title="键盘操作"></a>键盘操作</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/history.png"                      title="历史的操作"                ></p><ul><li><h3 id="历史操作"><a href="#历史操作" class="headerlink" title="历史操作"></a>历史操作</h3><ul><li><em><strong>history 操作，history | less |grep tldr</strong></em></li></ul></li><li><h3 id="权限security"><a href="#权限security" class="headerlink" title="权限security"></a>权限security</h3><ul><li><em><strong>change the mode chmod cmd 改变rwx属性可以使用八进制数字来表示也可以用字符 <font color=red><a class="link"   href="http://billie66.github.io/TLCL/book/chap10.html" >chmod <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></font></strong></em></li><li><em><strong>su and sudo su 就是以另一个身份运行shell 而sudo是以另一个身份执行命令 最大的区别是su会重建一个设立了环境 而sudo不会</strong></em></li><li><em><strong>chown 改变用户权限 目前使用不是很多</strong></em></li><li><em><strong>passwd 命令用作更改i密码</strong></em></li><li><em><strong><font color=pink>good in wsl2 额可以touch 创建文件 同时可以code 编辑code似乎有许多有趣的指令</font></strong></em></li><li><em><strong><font color=red>想要切换用户 也就是一个全新的bash的话 用 su -l doudou .eg 退出的时候使用 exit就可以了</font></strong></em></li><li><em><strong><font color=blue>至于使用创建用户的命令就是adduser name 注意名字不能以大写字母开头 doudou</font></strong></em></li></ul></li><li><h3 id="核心概念-Process-进程link"><a href="#核心概念-Process-进程link" class="headerlink" title="核心概念 Process 进程link"></a>核心概念 Process 进程<a class="link"   href="http://billie66.github.io/TLCL/book/chap11.html" >link <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h3><ul><li><em><strong>init kernel进行run&#x2F;etc里的script所以为什么可以更改的原因</strong></em></li><li><strong>ctrl + c 强制返回的一种方法</strong></li><li><em><strong><font color=pink>&#x2F;proc    &#x2F;sys 文件系统 可以查看相关硬件划分信息</font><br>备份文件的名字无关紧要，只要选择一个容易理解的文件名。扩展名 “.bak”、”.sav”、 “.old”和 “.orig” 都是用来指示备份文件的流行方法。哦，记住 cp 命令会默默地覆盖已经存在的同名文件。  bak stand for backup file</strong></em></li></ul></li><li><h3 id="Nano与其他文本编辑器"><a href="#Nano与其他文本编辑器" class="headerlink" title="Nano与其他文本编辑器"></a>Nano与其他<a class="link"   href="http://billie66.github.io/TLCL/book/chap12.html" >文本编辑器 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h3><ul><li><em><strong><font color=pink>之前学的很多bash的指令到很多编辑器里都是一样的</font></strong></em></li><li><em><strong><font color=pink>source .bashrc 生效指令</font></strong></em></li><li><em><strong><font color=pink>ctrl o in nano 保存</font></strong></em></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;TLCL&quot;&gt;&lt;a href=&quot;#TLCL&quot; class=&quot;headerlink&quot; title=&quot;TLCL&quot;&gt;&lt;/a&gt;TLCL&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;新的开始 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;今天怒创了两个用户-密码都是老密码</summary>
      
    
    
    
    
    <category term="LINUX" scheme="https://spikeihg.github.io/tags/LINUX/"/>
    
  </entry>
  
  <entry>
    <title>TGA_CXX</title>
    <link href="https://spikeihg.github.io/2023/09/22/TGA-CXX/"/>
    <id>https://spikeihg.github.io/2023/09/22/TGA-CXX/</id>
    <published>2023-09-22T07:21:07.000Z</published>
    <updated>2023-10-02T13:01:52.587Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TGA关于c"><a href="#TGA关于c" class="headerlink" title="TGA关于c++"></a><font color=seablue>TGA关于c++</font></h3><ul><li><h4 id="C-操作文件-这里记录一些相关要用的知识点-便于统一看"><a href="#C-操作文件-这里记录一些相关要用的知识点-便于统一看" class="headerlink" title="C++操作文件 这里记录一些相关要用的知识点 便于统一看"></a>C++操作文件 这里记录一些相关要用的知识点 便于统一看</h4><ul><li>**流访问，有open std::ios::binary ,.good(),.get(),.read()的一些参数 **</li><li><strong>重载函数规范有点忘记。</strong></li><li><strong>copy (stored data) to a different location, especially so as to protect against loss.  <font color=gold>dump in computer mean</font></strong></li><li><strong>ESCAPE SYMBOL 溢出符号</strong></li><li><strong><font color=seagreen>Run-length encode a lossless encode method  just to replace the runS(many values occurs consecutivelt) w12b2cd13e32 .eg</font></strong></li><li><img                       lazyload                     src="/images/loading.svg"                     data-src="/../images/const.png"                      alt="const只是语法检查 所以地址转换是一个编程漏洞"                ></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;TGA关于c&quot;&gt;&lt;a href=&quot;#TGA关于c&quot; class=&quot;headerlink&quot; title=&quot;TGA关于c++&quot;&gt;&lt;/a&gt;&lt;font color=seablue&gt;TGA关于c++&lt;/font&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;h4 id=&quot;C-操作文件-这里</summary>
      
    
    
    
    
    <category term="CXX" scheme="https://spikeihg.github.io/tags/CXX/"/>
    
  </entry>
  
  <entry>
    <title>CSAPP</title>
    <link href="https://spikeihg.github.io/2023/09/16/CSAPP/"/>
    <id>https://spikeihg.github.io/2023/09/16/CSAPP/</id>
    <published>2023-09-16T07:59:01.000Z</published>
    <updated>2023-10-05T05:45:21.613Z</updated>
    
    <content type="html"><![CDATA[<ul><li><h2 id="CSAPP"><a href="#CSAPP" class="headerlink" title="CSAPP"></a>CSAPP</h2><ul><li><h3 id="terms-colletion"><a href="#terms-colletion" class="headerlink" title="terms colletion"></a>terms colletion</h3><ul><li>snippet re-useble code part maybe name the directory</li></ul></li><li><h3 id="tldr"><a href="#tldr" class="headerlink" title="tldr"></a>tldr</h3><ul><li>to long didn’t read and a linux simplified manual cm</li></ul></li><li><p><a href="/doc/normal.pdf">Try</a></p></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;h2 id=&quot;CSAPP&quot;&gt;&lt;a href=&quot;#CSAPP&quot; class=&quot;headerlink&quot; title=&quot;CSAPP&quot;&gt;&lt;/a&gt;CSAPP&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;terms-colletion&quot;&gt;&lt;a href=&quot;#terms-co</summary>
      
    
    
    
    
    <category term="组成原理" scheme="https://spikeihg.github.io/tags/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
</feed>
